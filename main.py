import numpy as np
import os
import json
import tensorflow as tf
import time

# å¼•ç”¨ç°æœ‰æ¨¡å—
from entropy_utils import precompute_entropies, precompute_mutual_information
from agent import BandSelectionAgent
from reward_utils import calculate_reward

# ================= ğŸ”§ é…ç½®åŒºåŸŸ =================
# [å…³é”®] æŒ‡å‘ save_data.py è¾“å‡ºçš„æ–‡ä»¶å¤¹
DATA_DIR = r"I:\SPEDATA\NP_data"

# ç»“æœä¿å­˜é…ç½®
CONFIG_OUTPUT_FILE = "best_bands_config.json"
MODEL_CHECKPOINT_DIR = "checkpoints"

# DRL è¶…å‚æ•°
NUM_BANDS_TO_SELECT = 30  # æœ€ç»ˆé€‰æ‹©å¤šå°‘ä¸ªæ³¢æ®µ
TOTAL_EPISODES = 500  # è®­ç»ƒè½®æ•°
SAMPLE_SIZE = 10000  # é‡‡æ ·ç‚¹æ•°
ALPHA = 0.7  # å¥–åŠ±æƒé‡

# æ˜¾å­˜é…ç½®
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        tf.config.experimental.set_memory_growth(gpus[0], True)
        print("âœ… GPU æ˜¾å­˜æŒ‰éœ€åˆ†é…å·²å¯ç”¨")
    except RuntimeError as e:
        print(e)


# ================= ğŸ§  æ•°æ®åŠ è½½é€»è¾‘ =================

# å°†æ­¤å‡½æ•°æ›¿æ¢åŸæ¥çš„ load_representative_data_for_drl

def load_representative_data_for_drl():
    print("ğŸš€ [DRL] æ­£åœ¨åŠ è½½æ··åˆæ ·æœ¬ (PET + CC + PA)...")

    # === ä¿®æ”¹ 1: æ‰©å±•æ•°æ®é›†é…ç½®ï¼Œå¢åŠ  use_json æ ‡è®° ===
    dataset_configs = [
        # 1. PET æ–‡ä»¶å¤¹ (éœ€è¦ JSON åŒºåˆ†ç“¶ç‰‡å’Œæ‚è´¨)
        {
            "root": r"L:\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\train-PET",
            "json_subdir": "fake_images",
            "is_pet_folder": True,
            "use_json": True  # ä½¿ç”¨ JSON è§£æ
        },
        # 2. CC (çº¯æè´¨ï¼Œæ— éœ€ JSONï¼Œæ•´å¼ å›¾é™¤äº†èƒŒæ™¯éƒ½æ˜¯ CC)
        {
            "root": r"I:\SPEDATA\é«˜è°±ç›¸æœºæ•°æ®é›†\è®­ç»ƒé›†\no_PET\CC",
            "json_subdir": None,
            "is_pet_folder": False,
            "use_json": False  # ä¸ç”¨ JSONï¼Œè‡ªåŠ¨æå–
        },
        # 3. PA (çº¯æè´¨ï¼Œæ— éœ€ JSON)
        {
            "root": r"I:\SPEDATA\é«˜è°±ç›¸æœºæ•°æ®é›†\è®­ç»ƒé›†\no_PET\PA",
            "json_subdir": None,
            "is_pet_folder": False,
            "use_json": False
        }
    ]

    white = load_calibration_file(WHITE_REF_HDR)
    dark = load_calibration_file(DARK_REF_HDR)
    denom = (white - dark)
    denom[denom == 0] = 1e-6

    collected_X = []
    collected_y = []

    count_pet = 0
    count_hard_neg = 0  # PP, CC, PA
    count_soft_neg = 0  # èƒŒæ™¯

    # ç›®æ ‡é‡‡æ ·æ•°
    TARGET_PER_CLASS = 3000

    for config in dataset_configs:
        root_dir = config["root"]
        is_pet_source = config["is_pet_folder"]
        use_json = config["use_json"]  # è·å–æ ‡è®°

        if not os.path.exists(root_dir):
            print(f"âš ï¸ è·¯å¾„ä¸å­˜åœ¨è·³è¿‡: {root_dir}")
            continue

        files = [f for f in os.listdir(root_dir) if f.endswith('.spe')]

        for fname in files:
            # æå‰åœæ­¢
            if is_pet_source and count_pet >= TARGET_PER_CLASS and count_soft_neg >= TARGET_PER_CLASS: continue
            if not is_pet_source and count_hard_neg >= TARGET_PER_CLASS: continue

            try:
                # åŠ è½½å¹¶æ ¡å‡†
                hdr_path = os.path.join(root_dir, fname.replace('.spe', '.hdr'))
                if not os.path.exists(hdr_path): continue

                raw = np.array(envi.open(hdr_path, os.path.join(root_dir, fname)).load(), dtype=np.float32)

                # ç»´åº¦ä¿®æ­£
                if raw.shape[1] == 208 and raw.shape[2] != 208:
                    raw = np.transpose(raw, (0, 2, 1))

                # æ³¢æ®µå¯¹é½ (å¤„ç†å¯èƒ½çš„ 206/208 é—®é¢˜)
                if raw.shape[2] != denom.shape[2]:
                    # ç®€å•è£å‰ªæˆ–æŠ¥é”™ï¼Œè¿™é‡Œå‡è®¾å·²ç»å¯¹é½æˆ–ä½¿ç”¨ä¹‹å‰ save_data çš„é€»è¾‘
                    # ä¸ºç®€å•èµ·è§ï¼Œè¿™é‡Œå‡è®¾ç»´åº¦ä¸€è‡´ï¼Œå¦‚æœä¸ä¸€è‡´å»ºè®®å…ˆç”¨ save_data å¤„ç†æˆ npy
                    pass

                calib = (raw - dark) / denom

                mask = None

                # === ä¿®æ”¹ 2: åˆ†æƒ…å†µå¤„ç† Mask ===
                if use_json:
                    # åŸæœ‰é€»è¾‘ï¼šè¯»å– JSON
                    json_subdir = config["json_subdir"]
                    base_name = os.path.splitext(fname)[0]
                    json_path = os.path.join(root_dir, json_subdir, base_name + ".json")
                    if not os.path.exists(json_path):
                        json_path = os.path.join(root_dir, base_name + ".json")

                    if os.path.exists(json_path):
                        mask = get_mask_from_json(json_path, (calib.shape[0], calib.shape[1]))
                else:
                    # === æ–°å¢é€»è¾‘ï¼šè‡ªåŠ¨èƒŒæ™¯å»é™¤ ===
                    # è®¡ç®—å¹³å‡äº®åº¦
                    intensity = np.mean(calib, axis=2)
                    # é˜ˆå€¼ 0.05 (æ ¹æ®æ•°æ®è°ƒæ•´ï¼ŒèƒŒæ™¯é€šå¸¸æ¥è¿‘ 0)
                    fg_mask = (intensity > 0.05)

                    if np.sum(fg_mask) > 100:  # åªè¦æœ‰è¶³å¤Ÿçš„å‰æ™¯
                        mask = np.zeros((calib.shape[0], calib.shape[1]), dtype=np.uint8)
                        # æ ‡è®°ä¸º 2 (å¼ºè´Ÿæ ·æœ¬)
                        mask[fg_mask] = 2

                if mask is None: continue

                # === åç»­æå–é€»è¾‘ä¿æŒä¸å˜ ===
                flat_data = calib.reshape(-1, calib.shape[2])
                flat_mask = mask.reshape(-1)

                idx_pet = np.where(flat_mask == 1)[0]
                idx_mat = np.where(flat_mask == 2)[0]  # CC, PA, PP éƒ½åœ¨è¿™é‡Œ
                idx_bg = np.where(flat_mask == 0)[0]

                # PET
                if is_pet_source and len(idx_pet) > 0 and count_pet < TARGET_PER_CLASS:
                    take = min(len(idx_pet), 200)
                    sel = np.random.choice(idx_pet, take, replace=False)
                    collected_X.append(flat_data[sel])
                    collected_y.append(np.ones(take))  # y=1
                    count_pet += take

                # å¼ºè´Ÿæ ·æœ¬ (CC, PA, PP) -> y=0
                if len(idx_mat) > 0 and count_hard_neg < TARGET_PER_CLASS:
                    take = min(len(idx_mat), 200)
                    sel = np.random.choice(idx_mat, take, replace=False)
                    collected_X.append(flat_data[sel])
                    collected_y.append(np.zeros(take))  # y=0
                    count_hard_neg += take

                # èƒŒæ™¯ -> y=0
                if is_pet_source and len(idx_bg) > 0 and count_soft_neg < TARGET_PER_CLASS:
                    take = min(len(idx_bg), 100)
                    sel = np.random.choice(idx_bg, take, replace=False)
                    collected_X.append(flat_data[sel])
                    collected_y.append(np.zeros(take))  # y=0
                    count_soft_neg += take

            except Exception as e:
                # print(f"Skipping {fname}: {e}")
                pass

    if not collected_X: raise ValueError("æ²¡æœ‰åŠ è½½åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥è·¯å¾„å’Œæ ¡å‡†æ–‡ä»¶ï¼")

    X = np.concatenate(collected_X, axis=0)
    y = np.concatenate(collected_y, axis=0)

    print(f"âœ… DRL é‡‡æ ·å®Œæˆ: PET={np.sum(y == 1)}, Non-PET(CC+PA+BG)={np.sum(y == 0)}")
    return X, y

# ================= ğŸš€ ä¸»è®­ç»ƒæµç¨‹ =================


import glob


def load_data_from_npy(data_dir, total_samples=10000):
    """
    ä» save_data.py ç”Ÿæˆçš„ .npy æ–‡ä»¶ä¸­åŠ è½½æ•°æ®
    PET æ–‡ä»¶å¤¹ -> æ ‡ç­¾ 1
    å…¶ä»–æ–‡ä»¶å¤¹ (CC, PA, PP, OTHER) -> æ ‡ç­¾ 0
    """
    print(f"ğŸš€ [DRL] æ­£åœ¨ä» {data_dir} åŠ è½½ .npy æ•°æ®...")

    if not os.path.exists(data_dir):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ•°æ®ç›®å½•: {data_dir}")

    all_files = glob.glob(os.path.join(data_dir, "**", "*.npy"), recursive=True)
    if not all_files:
        raise ValueError("âŒ ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ° .npy æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ save_data.py")

    X_list = []
    y_list = []

    # ç®€å•çš„å¹³è¡¡é‡‡æ ·é€»è¾‘
    pet_files = [f for f in all_files if "PET" in os.path.dirname(f)]
    other_files = [f for f in all_files if "PET" not in os.path.dirname(f)]

    print(f"   å‘ç° PET æ–‡ä»¶: {len(pet_files)} ä¸ª, é PET æ–‡ä»¶: {len(other_files)} ä¸ª")

    # æ¯ä¸ªç±»åˆ«é‡‡æ ·çš„ç›®æ ‡æ•°é‡
    target_per_class = total_samples // 2

    def sample_from_files(file_list, target_count, label):
        current_count = 0
        collected_x = []

        # éšæœºæ‰“ä¹±æ–‡ä»¶é¡ºåº
        np.random.shuffle(file_list)

        for f in file_list:
            if current_count >= target_count: break
            try:
                data = np.load(f)  # shape (H, W, Bands)
                # å±•å¹³
                flat = data.reshape(-1, data.shape[2])

                # ä»æ¯å¼ å›¾ä¸­éšæœºå– 500 ä¸ªç‚¹ (é¿å…å•å¼ å›¾ä¸»å¯¼)
                n_take = min(len(flat), 500)
                idx = np.random.choice(len(flat), n_take, replace=False)

                collected_x.append(flat[idx])
                current_count += n_take
            except Exception as e:
                print(f"âš ï¸ è¯»å–é”™è¯¯ {f}: {e}")

        if not collected_x: return np.array([]), np.array([])

        X_part = np.concatenate(collected_x, axis=0)
        y_part = np.full(len(X_part), label)

        # å¦‚æœé‡‡å¤šäº†ï¼Œæˆªæ–­
        if len(X_part) > target_count:
            idx = np.random.choice(len(X_part), target_count, replace=False)
            X_part = X_part[idx]
            y_part = y_part[idx]

        return X_part, y_part

    # é‡‡æ · PET (Label 1)
    X_pos, y_pos = sample_from_files(pet_files, target_per_class, 1)

    # é‡‡æ · éPET (Label 0)
    X_neg, y_neg = sample_from_files(other_files, target_per_class, 0)

    if len(X_pos) == 0 or len(X_neg) == 0:
        raise ValueError("âŒ é‡‡æ ·å¤±è´¥ï¼šæŸä¸€ç±»æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ .npy æ–‡ä»¶è·¯å¾„ç»“æ„")

    X = np.concatenate([X_pos, X_neg], axis=0)
    y = np.concatenate([y_pos, y_neg], axis=0)

    # å†æ¬¡æ‰“ä¹±
    idx = np.arange(len(X))
    np.random.shuffle(idx)

    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: æ€»æ•° {len(X)}, æ­£æ ·æœ¬ {np.sum(y == 1)}, è´Ÿæ ·æœ¬ {np.sum(y == 0)}")
    return X[idx], y[idx]








if __name__ == "__main__":
    if not os.path.exists(MODEL_CHECKPOINT_DIR):
        os.makedirs(MODEL_CHECKPOINT_DIR)

    # 1. åŠ è½½æ•°æ®
    X_sample, y_sample = load_data_from_npy(DATA_DIR, SAMPLE_SIZE)

    num_bands = X_sample.shape[1]
    print(f"ğŸ” æ³¢æ®µæ€»æ•°: {num_bands}")

    # 2. é¢„è®¡ç®—ç†µå’Œäº’ä¿¡æ¯
    print("â³ æ­£åœ¨é¢„è®¡ç®—äº’ä¿¡æ¯ (è¿™å†³å®šäº†æ³¢æ®µçš„åˆ¤åˆ«åŠ›)...")
    entropies = precompute_entropies(X_sample)

    # äº’ä¿¡æ¯ç®—æ³•ä¼šè‡ªåŠ¨å¯»æ‰¾èƒ½åŒºåˆ†æ‰€æœ‰ç±»åˆ«çš„æ³¢æ®µ
    mi_matrix = precompute_mutual_information(X_sample, y_sample)

    # å½’ä¸€åŒ–
    if np.max(entropies) != np.min(entropies):
        entropies = (entropies - np.min(entropies)) / (np.max(entropies) - np.min(entropies))
    if np.max(mi_matrix) != np.min(mi_matrix):
        mi_matrix = (mi_matrix - np.min(mi_matrix)) / (np.max(mi_matrix) - np.min(mi_matrix))

    print("âœ… äº’ä¿¡æ¯è®¡ç®—å®Œæ¯•ã€‚")

    # 3. åˆå§‹åŒ– DRL Agent
    agent = BandSelectionAgent(num_bands)

    best_reward = -np.inf
    best_bands = []

    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ DRL Agent ({TOTAL_EPISODES} Episodes)...")
    start_time = time.time()

    for e in range(TOTAL_EPISODES):
        state = np.zeros(num_bands)
        selected_bands = []
        episode_reward = 0

        for t in range(NUM_BANDS_TO_SELECT):
            # --- [ä¿®å¤æ ¸å¿ƒ] ---
            # åŸä»£ç : action = agent.act(state, available_bands=range(num_bands))
            # ä¿®æ­£ä¸º: ä½¿ç”¨ get_action å¹¶ä¼ å…¥ selected_bands ä»¥ä¾¿å±è”½å·²é€‰æ³¢æ®µ
            action = agent.get_action(state, selected_bands)
            # ------------------

            # å¥–åŠ±è®¡ç®—
            reward = calculate_reward(selected_bands, action, entropies, mi_matrix, alpha=ALPHA)

            next_state = state.copy()
            next_state[action] = 1
            done = (len(selected_bands) == NUM_BANDS_TO_SELECT - 1)

            agent.remember(state, action, reward, next_state, done)
            agent.train()

            state = next_state
            selected_bands.append(action)
            episode_reward += reward

            if done:
                agent.update_target_network()
                break

        # æ¢ç´¢ç‡è¡°å‡
        if agent.epsilon > agent.epsilon_min:
            agent.epsilon *= agent.epsilon_decay

        # è®°å½•æœ€ä½³
        if episode_reward > best_reward:
            best_reward = episode_reward
            best_bands = sorted(selected_bands)

        if (e + 1) % 10 == 0:
            print(
                f"Episode {e + 1}/{TOTAL_EPISODES} | Reward: {episode_reward:.4f} | Epsilon: {agent.epsilon:.2f} | Best Bands: {len(best_bands)}")

    total_time = time.time() - start_time
    print("\n" + "=" * 50)
    print(f"ğŸ† è®­ç»ƒç»“æŸ (è€—æ—¶ {total_time / 60:.1f} min)")
    print(f"ğŸ’ æœ€ä½³æ³¢æ®µç»„åˆ (Reward: {best_reward:.4f}):")
    print(best_bands)
    print("=" * 50)

    # 4. ä¿å­˜ç»“æœ
    output_data = {
        "selected_bands": [int(b) for b in best_bands],
        "reward": float(best_reward)
    }

    with open(CONFIG_OUTPUT_FILE, 'w') as f:
        json.dump(output_data, f, indent=4)

    print(f"ğŸ’¾ æ³¢æ®µé…ç½®å·²ä¿å­˜è‡³: {CONFIG_OUTPUT_FILE}")