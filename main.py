import numpy as np
import os
import json
import tensorflow as tf
import time
from visualization import visualize_spectral_selection

# å¼•ç”¨ç°æœ‰æ¨¡å—
from entropy_utils import precompute_entropies, precompute_mutual_information
from agent import BandSelectionAgent
from reward_utils import calculate_reward

# ================= ğŸ”§ é…ç½®åŒºåŸŸ =================
# [å…³é”®] æŒ‡å‘ save_data.py è¾“å‡ºçš„æ–‡ä»¶å¤¹
DATA_DIR = r"E:\SPEDATA\NP_data"

# ç»“æœä¿å­˜é…ç½®
CONFIG_OUTPUT_FILE = "best_bands_config.json"
MODEL_CHECKPOINT_DIR = "checkpoints"

# DRL è¶…å‚æ•°
NUM_BANDS_TO_SELECT = 30  # æœ€ç»ˆé€‰æ‹©å¤šå°‘ä¸ªæ³¢æ®µ
TOTAL_EPISODES = 500  # è®­ç»ƒè½®æ•°
SAMPLE_SIZE = 10000  # é‡‡æ ·ç‚¹æ•°
ALPHA = 0.7  # å¥–åŠ±æƒé‡

# æ˜¾å­˜é…ç½®
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        tf.config.experimental.set_memory_growth(gpus[0], True)
        print("âœ… GPU æ˜¾å­˜æŒ‰éœ€åˆ†é…å·²å¯ç”¨")
    except RuntimeError as e:
        print(e)


# ================= ğŸ§  æ•°æ®åŠ è½½é€»è¾‘ =================

# å°†æ­¤å‡½æ•°æ›¿æ¢åŸæ¥çš„ load_representative_data_for_drl

def load_representative_data_for_drl():
    print("ğŸš€ [DRL] æ­£åœ¨åŠ è½½æ··åˆæ ·æœ¬ (PET + CC + PA)...")

    # === ä¿®æ”¹ 1: æ‰©å±•æ•°æ®é›†é…ç½®ï¼Œå¢åŠ  use_json æ ‡è®° ===
    dataset_configs = [
        # 1. PET æ–‡ä»¶å¤¹ (éœ€è¦ JSON åŒºåˆ†ç“¶ç‰‡å’Œæ‚è´¨)
        {
            "root": r"M:\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\train-PET",
            "json_subdir": "fake_images",
            "is_pet_folder": True,
            "use_json": True  # ä½¿ç”¨ JSON è§£æ
        },
        # 2. CC (çº¯æè´¨ï¼Œæ— éœ€ JSONï¼Œæ•´å¼ å›¾é™¤äº†èƒŒæ™¯éƒ½æ˜¯ CC)
        {
            "root": r"E:\SPEDATA\é«˜è°±ç›¸æœºæ•°æ®é›†\è®­ç»ƒé›†\no_PET\CC",
            "json_subdir": None,
            "is_pet_folder": False,
            "use_json": False  # ä¸ç”¨ JSONï¼Œè‡ªåŠ¨æå–
        },
        # 3. PA (çº¯æè´¨ï¼Œæ— éœ€ JSON)
        {
            "root": r"E:\SPEDATA\é«˜è°±ç›¸æœºæ•°æ®é›†\è®­ç»ƒé›†\no_PET\PA",
            "json_subdir": None,
            "is_pet_folder": False,
            "use_json": False
        }
    ]

    white = load_calibration_file(WHITE_REF_HDR)
    dark = load_calibration_file(DARK_REF_HDR)
    denom = (white - dark)
    denom[denom == 0] = 1e-6

    collected_X = []
    collected_y = []

    count_pet = 0
    count_hard_neg = 0  # PP, CC, PA
    count_soft_neg = 0  # èƒŒæ™¯

    # ç›®æ ‡é‡‡æ ·æ•°
    TARGET_PER_CLASS = 3000

    for config in dataset_configs:
        root_dir = config["root"]
        is_pet_source = config["is_pet_folder"]
        use_json = config["use_json"]  # è·å–æ ‡è®°

        if not os.path.exists(root_dir):
            print(f"âš ï¸ è·¯å¾„ä¸å­˜åœ¨è·³è¿‡: {root_dir}")
            continue

        files = [f for f in os.listdir(root_dir) if f.endswith('.spe')]

        for fname in files:
            # æå‰åœæ­¢
            if is_pet_source and count_pet >= TARGET_PER_CLASS and count_soft_neg >= TARGET_PER_CLASS: continue
            if not is_pet_source and count_hard_neg >= TARGET_PER_CLASS: continue

            try:
                # åŠ è½½å¹¶æ ¡å‡†
                hdr_path = os.path.join(root_dir, fname.replace('.spe', '.hdr'))
                if not os.path.exists(hdr_path): continue

                raw = np.array(envi.open(hdr_path, os.path.join(root_dir, fname)).load(), dtype=np.float32)

                # ç»´åº¦ä¿®æ­£
                if raw.shape[1] == 208 and raw.shape[2] != 208:
                    raw = np.transpose(raw, (0, 2, 1))

                # æ³¢æ®µå¯¹é½ (å¤„ç†å¯èƒ½çš„ 206/208 é—®é¢˜)
                if raw.shape[2] != denom.shape[2]:
                    # ç®€å•è£å‰ªæˆ–æŠ¥é”™ï¼Œè¿™é‡Œå‡è®¾å·²ç»å¯¹é½æˆ–ä½¿ç”¨ä¹‹å‰ save_data çš„é€»è¾‘
                    # ä¸ºç®€å•èµ·è§ï¼Œè¿™é‡Œå‡è®¾ç»´åº¦ä¸€è‡´ï¼Œå¦‚æœä¸ä¸€è‡´å»ºè®®å…ˆç”¨ save_data å¤„ç†æˆ npy
                    pass

                calib = (raw - dark) / denom

                mask = None

                # === ä¿®æ”¹ 2: åˆ†æƒ…å†µå¤„ç† Mask ===
                if use_json:
                    # åŸæœ‰é€»è¾‘ï¼šè¯»å– JSON
                    json_subdir = config["json_subdir"]
                    base_name = os.path.splitext(fname)[0]
                    json_path = os.path.join(root_dir, json_subdir, base_name + ".json")
                    if not os.path.exists(json_path):
                        json_path = os.path.join(root_dir, base_name + ".json")

                    if os.path.exists(json_path):
                        mask = get_mask_from_json(json_path, (calib.shape[0], calib.shape[1]))
                else:
                    # === æ–°å¢é€»è¾‘ï¼šè‡ªåŠ¨èƒŒæ™¯å»é™¤ ===
                    # è®¡ç®—å¹³å‡äº®åº¦
                    intensity = np.mean(calib, axis=2)
                    # é˜ˆå€¼ 0.05 (æ ¹æ®æ•°æ®è°ƒæ•´ï¼ŒèƒŒæ™¯é€šå¸¸æ¥è¿‘ 0)
                    fg_mask = (intensity > 0.05)

                    if np.sum(fg_mask) > 100:  # åªè¦æœ‰è¶³å¤Ÿçš„å‰æ™¯
                        mask = np.zeros((calib.shape[0], calib.shape[1]), dtype=np.uint8)
                        # æ ‡è®°ä¸º 2 (å¼ºè´Ÿæ ·æœ¬)
                        mask[fg_mask] = 2

                if mask is None: continue

                # === åç»­æå–é€»è¾‘ä¿æŒä¸å˜ ===
                flat_data = calib.reshape(-1, calib.shape[2])
                flat_mask = mask.reshape(-1)

                idx_pet = np.where(flat_mask == 1)[0]
                idx_mat = np.where(flat_mask == 2)[0]  # CC, PA, PP éƒ½åœ¨è¿™é‡Œ
                idx_bg = np.where(flat_mask == 0)[0]

                # PET
                if is_pet_source and len(idx_pet) > 0 and count_pet < TARGET_PER_CLASS:
                    take = min(len(idx_pet), 200)
                    sel = np.random.choice(idx_pet, take, replace=False)
                    collected_X.append(flat_data[sel])
                    collected_y.append(np.ones(take))  # y=1
                    count_pet += take

                # å¼ºè´Ÿæ ·æœ¬ (CC, PA, PP) -> y=0
                if len(idx_mat) > 0 and count_hard_neg < TARGET_PER_CLASS:
                    take = min(len(idx_mat), 200)
                    sel = np.random.choice(idx_mat, take, replace=False)
                    collected_X.append(flat_data[sel])
                    collected_y.append(np.zeros(take))  # y=0
                    count_hard_neg += take

                # èƒŒæ™¯ -> y=0
                if is_pet_source and len(idx_bg) > 0 and count_soft_neg < TARGET_PER_CLASS:
                    take = min(len(idx_bg), 100)
                    sel = np.random.choice(idx_bg, take, replace=False)
                    collected_X.append(flat_data[sel])
                    collected_y.append(np.zeros(take))  # y=0
                    count_soft_neg += take

            except Exception as e:
                # print(f"Skipping {fname}: {e}")
                pass

    if not collected_X: raise ValueError("æ²¡æœ‰åŠ è½½åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥è·¯å¾„å’Œæ ¡å‡†æ–‡ä»¶ï¼")

    X = np.concatenate(collected_X, axis=0)
    y = np.concatenate(collected_y, axis=0)

    print(f"âœ… DRL é‡‡æ ·å®Œæˆ: PET={np.sum(y == 1)}, Non-PET(CC+PA+BG)={np.sum(y == 0)}")
    return X, y

# ================= ğŸš€ ä¸»è®­ç»ƒæµç¨‹ =================


import glob


def load_data_from_npy(data_dir, total_samples=10000):
    """
    [ä¼˜åŒ–ç‰ˆ] åŠ è½½æ•°æ®å¹¶èµ‹äºˆå¤šåˆ†ç±»æ ‡ç­¾ï¼Œç”¨äº DRL ç‰¹å¾ç­›é€‰
    æ ‡ç­¾å®šä¹‰: 0=èƒŒæ™¯/å…¶ä»–, 1=PET, 2=CC, 3=PA
    """
    print(f"ğŸš€ [DRL] æ­£åœ¨ä» {data_dir} åŠ è½½å¤šæè´¨æ•°æ® (PET/CC/PA)...")

    if not os.path.exists(data_dir):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ•°æ®ç›®å½•: {data_dir}")

    # æŸ¥æ‰¾å„ç±»åˆ«çš„æ–‡ä»¶å¤¹ (ç¡®ä¿ save_data.py å·²ç»æŒ‰æ–‡ä»¶å¤¹åˆ†å¥½äº†)
    # å‡è®¾ save_data.py ç”Ÿæˆçš„ç»“æ„æ˜¯: data_dir/PET, data_dir/CC, data_dir/PA
    import glob
    all_files = glob.glob(os.path.join(data_dir, "**", "*.npy"), recursive=True)

    # å®šä¹‰ç±»åˆ«å¯¹åº”çš„å…³é”®å­—å’Œæ ‡ç­¾
    class_config = [
        {"key": "PET", "label": 1},
        {"key": "CC", "label": 2},
        {"key": "PA", "label": 3}
        # å…¶ä»–æœªåŒ¹é…çš„é»˜è®¤ä¸º 0
    ]

    # åˆ†é…æ–‡ä»¶åˆ°ç±»åˆ«
    file_groups = {0: [], 1: [], 2: [], 3: []}

    for f in all_files:
        path_upper = os.path.dirname(f).upper()
        assigned = False
        for cfg in class_config:
            if cfg["key"] in path_upper:
                file_groups[cfg["label"]].append(f)
                assigned = True
                break
        if not assigned:
            file_groups[0].append(f)  # å½’ä¸ºèƒŒæ™¯æˆ–å…¶ä»–

    print(
        f"   ğŸ“Š æ–‡ä»¶åˆ†å¸ƒ: PET={len(file_groups[1])}, CC={len(file_groups[2])}, PA={len(file_groups[3])}, Other={len(file_groups[0])}")

    # å‡è¡¡é‡‡æ ·ï¼šä¸ºäº†è®© Agent é‡è§†æ¯ç§æè´¨ï¼Œæ¯ç±»é‡‡æ ·æ•°é‡åº”å¤§è‡´ç›¸ç­‰
    target_per_class = total_samples // 4

    X_list = []
    y_list = []

    def sample_category(file_list, label, count):
        if not file_list: return
        collected_x = []
        current_count = 0
        np.random.shuffle(file_list)

        for f in file_list:
            if current_count >= count: break
            try:
                data = np.load(f)  # shape (H, W, Bands)
                flat = data.reshape(-1, data.shape[2])

                # ç®€å•èƒŒæ™¯å»é™¤ (å‡è®¾å€¼å¾ˆå°çš„æ˜¯èƒŒæ™¯ï¼Œå¦‚æœæœ¬æ¥å°±æ˜¯èƒŒæ™¯ç±»åˆ™ä¸å»é™¤)
                if label != 0:
                    intensity = np.mean(flat, axis=1)
                    flat = flat[intensity > 0.05]  # è¿‡æ»¤çº¯é»‘èƒŒæ™¯

                if len(flat) == 0: continue

                # éšæœºé‡‡æ ·ç‚¹
                take = min(len(flat), 500)
                idx = np.random.choice(len(flat), take, replace=False)
                collected_x.append(flat[idx])
                current_count += take
            except:
                pass

        if collected_x:
            X_part = np.concatenate(collected_x, axis=0)
            # å†æ¬¡æˆªæ–­åˆ°ç›®æ ‡æ•°é‡
            if len(X_part) > count:
                X_part = X_part[:count]
            y_part = np.full(len(X_part), label)
            X_list.append(X_part)
            y_list.append(y_part)

    # å¯¹æ¯ä¸€ç±»è¿›è¡Œé‡‡æ ·
    for label, files in file_groups.items():
        sample_category(files, label, target_per_class)

    if not X_list:
        raise ValueError("âŒ æœªåŠ è½½åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼")

    X = np.concatenate(X_list, axis=0)
    y = np.concatenate(y_list, axis=0)

    # æ‰“ä¹±æ•°æ®
    idx = np.arange(len(X))
    np.random.shuffle(idx)

    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: æ€»æ ·æœ¬ {len(X)}, åŒ…å«æ ‡ç­¾ {np.unique(y)}")
    return X[idx], y[idx]







if __name__ == "__main__":
    if not os.path.exists(MODEL_CHECKPOINT_DIR):
        os.makedirs(MODEL_CHECKPOINT_DIR)

    # 1. åŠ è½½æ•°æ®
    X_sample, y_sample = load_data_from_npy(DATA_DIR, SAMPLE_SIZE)

    # --- æ–°å¢ï¼šæ¸…æ´—æ— æ•ˆå€¼ ---
    print("ğŸ§¹ æ­£åœ¨æ¸…ç†å¼‚å¸¸æ•°å€¼ (NaN/Inf)...")
    # å°† Inf æ›¿æ¢ä¸º 0ï¼Œå°† NaN æ›¿æ¢ä¸º 0
    X_sample = np.nan_to_num(X_sample, nan=0.0, posinf=0.0, neginf=0.0)

    # å¯é€‰ï¼šå‰”é™¤æç«¯å¼‚å¸¸å€¼ï¼ˆä¾‹å¦‚åå°„ç‡ä¸åº”å¤§äº 2 æˆ–å°äº 0ï¼‰
    X_sample = np.clip(X_sample, 0.0, 2.0)
    # -----------------------

    num_bands = X_sample.shape[1]
    num_bands = X_sample.shape[1]
    print(f"ğŸ” æ³¢æ®µæ€»æ•°: {num_bands}")

    # 2. é¢„è®¡ç®—ç†µå’Œäº’ä¿¡æ¯
    print("â³ æ­£åœ¨é¢„è®¡ç®—äº’ä¿¡æ¯ (è¿™å†³å®šäº†æ³¢æ®µçš„åˆ¤åˆ«åŠ›)...")
    entropies = precompute_entropies(X_sample)

    # äº’ä¿¡æ¯ç®—æ³•ä¼šè‡ªåŠ¨å¯»æ‰¾èƒ½åŒºåˆ†æ‰€æœ‰ç±»åˆ«çš„æ³¢æ®µ
    mi_matrix = precompute_mutual_information(X_sample, y_sample)

    # å½’ä¸€åŒ–
    if np.max(entropies) != np.min(entropies):
        entropies = (entropies - np.min(entropies)) / (np.max(entropies) - np.min(entropies))
    if np.max(mi_matrix) != np.min(mi_matrix):
        mi_matrix = (mi_matrix - np.min(mi_matrix)) / (np.max(mi_matrix) - np.min(mi_matrix))

    print("âœ… äº’ä¿¡æ¯è®¡ç®—å®Œæ¯•ã€‚")

    # 3. åˆå§‹åŒ– DRL Agent
    agent = BandSelectionAgent(num_bands)

    best_reward = -np.inf
    best_bands = []

    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ DRL Agent ({TOTAL_EPISODES} Episodes)...")
    start_time = time.time()

    for e in range(TOTAL_EPISODES):
        state = np.zeros(num_bands)
        selected_bands = []
        episode_reward = 0

        for t in range(NUM_BANDS_TO_SELECT):
            # --- [ä¿®å¤æ ¸å¿ƒ] ---
            # åŸä»£ç : action = agent.act(state, available_bands=range(num_bands))
            # ä¿®æ­£ä¸º: ä½¿ç”¨ get_action å¹¶ä¼ å…¥ selected_bands ä»¥ä¾¿å±è”½å·²é€‰æ³¢æ®µ
            action = agent.get_action(state, selected_bands)
            # ------------------

            # å¥–åŠ±è®¡ç®—
            reward = calculate_reward(selected_bands, action, entropies, mi_matrix, alpha=ALPHA)

            next_state = state.copy()
            next_state[action] = 1
            done = (len(selected_bands) == NUM_BANDS_TO_SELECT - 1)

            agent.remember(state, action, reward, next_state, done)
            agent.train()

            state = next_state
            selected_bands.append(action)
            episode_reward += reward

            if done:
                agent.update_target_network()
                break

        # æ¢ç´¢ç‡è¡°å‡
        if agent.epsilon > agent.epsilon_min:
            agent.epsilon *= agent.epsilon_decay

        # è®°å½•æœ€ä½³
        if episode_reward > best_reward:
            best_reward = episode_reward
            best_bands = sorted(selected_bands)

        if (e + 1) % 10 == 0:
            print(
                f"Episode {e + 1}/{TOTAL_EPISODES} | Reward: {episode_reward:.4f} | Epsilon: {agent.epsilon:.2f} | Best Bands: {len(best_bands)}")

    total_time = time.time() - start_time
    print("\n" + "=" * 50)
    print(f"ğŸ† è®­ç»ƒç»“æŸ (è€—æ—¶ {total_time / 60:.1f} min)")
    print(f"ğŸ’ æœ€ä½³æ³¢æ®µç»„åˆ (Reward: {best_reward:.4f}):")
    print(best_bands)
    print("=" * 50)

    # 4. ä¿å­˜ç»“æœ
    output_data = {
        "selected_bands": [int(b) for b in best_bands],
        "reward": float(best_reward)
    }

    with open(CONFIG_OUTPUT_FILE, 'w') as f:
        json.dump(output_data, f, indent=4)

    print(f"ğŸ’¾ æ³¢æ®µé…ç½®å·²ä¿å­˜è‡³: {CONFIG_OUTPUT_FILE}")
    # ... (ä¹‹å‰çš„ä»£ç : ä¿å­˜ json) ...

    with open(CONFIG_OUTPUT_FILE, 'w') as f:
        json.dump(output_data, f, indent=4)

    print(f"ğŸ’¾ æ³¢æ®µé…ç½®å·²ä¿å­˜è‡³: {CONFIG_OUTPUT_FILE}")

    # ================= ğŸ†• æ–°å¢å¯è§†åŒ–è°ƒç”¨ =================
    print("-" * 50)
    print("ğŸ–¼ï¸ æ­£åœ¨ç”Ÿæˆç»“æœå¯è§†åŒ–...")

    # ä½¿ç”¨ä¹‹å‰åŠ è½½çš„ X_sample, y_sample æ•°æ®
    # X_sample åŒ…å«äº† PET, CC, PA çš„æ··åˆæ•°æ®
    visualize_spectral_selection(
        X_sample,
        y_sample,
        best_bands,
        save_path="final_spectral_analysis.png"
    )

    print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼è¯·æŸ¥çœ‹ç”Ÿæˆçš„ .png å›¾ç‰‡ã€‚")
    # ====================================================