# hsi_predictor_core.py
import os
import time
import json
import numpy as np
import spectral.io.envi as envi
import cv2

# ================= 0. ç¯å¢ƒæ£€æµ‹ =================
try:
    import tensorflow as tf
    from tensorflow.keras import layers, models

    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False
    print("âš ï¸ TensorFlow not available.")

try:
    import onnxruntime as ort

    ONNX_AVAILABLE = True
except ImportError:
    ONNX_AVAILABLE = False
    print("âš ï¸ ONNX Runtime not available.")


def configure_gpu_memory():
    """æ˜¾å­˜é˜²çˆ†é…ç½®"""
    if TF_AVAILABLE:
        gpus = tf.config.experimental.list_physical_devices('GPU')
        if gpus:
            try:
                for gpu in gpus:
                    tf.config.experimental.set_memory_growth(gpu, True)
            except RuntimeError:
                pass


def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):
    """Keras æ¨¡å‹åŠ è½½éœ€è¦çš„è‡ªå®šä¹‰å±‚"""
    x = layers.LayerNormalization(epsilon=1e-6)(inputs)
    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)
    x = layers.Dropout(dropout)(x)
    res = x + inputs
    x = layers.LayerNormalization(epsilon=1e-6)(res)
    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation="relu")(x)
    x = layers.Dropout(dropout)(x)
    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)
    return x + res


# ================= 1. æ ¸å¿ƒé¢„æµ‹å¼•æ“ =================
class HSIPredictor:
    def __init__(self, model_path, config_path, white_ref_path, dark_ref_path):
        configure_gpu_memory()

        self.model_path = model_path
        self.config_path = config_path
        self.model_type = "unknown"
        self.tf_model = None
        self.onnx_session = None
        self.input_name = None

        # åŠ è½½é…ç½®ä¸æ¨¡å‹
        initial_bands = self._load_band_config()
        self._load_model(model_path)
        self.selected_bands = self._adapt_input_shape(initial_bands)

        # åŠ è½½æ ¡å‡†
        print("ğŸ“¥ Loading calibration files...")
        self.white_ref = self._load_spe_calibration(white_ref_path)
        self.dark_ref = self._load_spe_calibration(dark_ref_path)

        # é¢„çƒ­
        print("ğŸ”¥ Warming up model...")
        dummy = np.zeros((1, len(self.selected_bands)), dtype=np.float32)
        try:
            self._internal_predict(dummy)
        except Exception as e:
            print(f"âŒ Warm-up warning: {e}")

    def _load_band_config(self):
        if not os.path.exists(self.config_path): return []
        with open(self.config_path, 'r') as f:
            return json.load(f).get("selected_bands", [])

    def _load_model(self, path):
        if path.endswith(".onnx"):
            if not ONNX_AVAILABLE: raise ImportError("Need onnxruntime")
            self.model_type = "onnx"
            try:
                self.onnx_session = ort.InferenceSession(path,
                                                         providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])
            except:
                self.onnx_session = ort.InferenceSession(path, providers=['CPUExecutionProvider'])
            self.input_name = self.onnx_session.get_inputs()[0].name
        elif path.endswith(".h5"):
            if not TF_AVAILABLE: raise ImportError("Need tensorflow")
            self.model_type = "keras"
            self.tf_model = tf.keras.models.load_model(path,
                                                       custom_objects={'transformer_encoder': transformer_encoder})
        else:
            raise ValueError("Unknown model format")

    def _adapt_input_shape(self, config_bands):
        # ç®€åŒ–ç‰ˆç»´åº¦é€‚é…
        expected = 0
        if self.model_type == "keras":
            expected = self.tf_model.input_shape[-1]
        elif self.model_type == "onnx":
            shape = self.onnx_session.get_inputs()[0].shape
            expected = shape[1] if len(shape) == 2 else len(config_bands)

        if expected != len(config_bands) and isinstance(expected, int):
            print(f"âš ï¸ Band mismatch: Model {expected} vs Config {len(config_bands)}. Using Model count.")
            return list(range(expected))
        return config_bands

    def _internal_predict(self, input_data):
        if self.model_type == "keras":
            return self.tf_model.predict(input_data, batch_size=4096, verbose=0)
        elif self.model_type == "onnx":
            return self.onnx_session.run(None, {self.input_name: input_data.astype(np.float32)})[0]

    def _resolve_paths(self, file_path):
        base = os.path.splitext(file_path)[0]
        return base + ".hdr", base + ".spe"

    def _fix_header(self, hdr):
        if not os.path.exists(hdr): return
        try:
            with open(hdr, 'r', encoding='utf-8', errors='ignore') as f:
                if 'byte order' not in f.read().lower():
                    with open(hdr, 'a') as fa: fa.write('\nbyte order = 0')
        except:
            pass

    def _load_spe_calibration(self, path):
        hdr, spe = self._resolve_paths(path)
        self._fix_header(hdr)
        if not os.path.exists(spe): raise FileNotFoundError(f"Missing {spe}")
        return np.mean(envi.open(hdr, spe).load(), axis=(0, 1)).astype(np.float32)

    def predict_image(self, input_path, brightness_thresh=0.01, conf_thresh=0.85):
        t_start = time.time()

        # 1. è¯»å–æ•°æ®
        hdr, spe = self._resolve_paths(input_path)
        self._fix_header(hdr)

        try:
            raw_img = envi.open(hdr, spe).load()
        except Exception as e:
            return None, None, {"error": str(e)}

        # ç»´åº¦ä¿®æ­£ [H, Bands, W] -> [H, W, Bands]
        if raw_img.shape[1] > 200 and raw_img.shape[1] < 250 and raw_img.shape[2] != raw_img.shape[1]:
            raw_img = np.transpose(raw_img, (0, 2, 1))

        H, W, B = raw_img.shape

        # 2. å‡†å¤‡ "ç”»å¸ƒ"
        # ç”¨äºç”Ÿæˆçƒ­åŠ›å›¾çš„ç°åº¦åº•å›¾ï¼Œé»˜è®¤å…¨ 0
        heatmap_canvas = np.zeros((H, W), dtype=np.float32)

        # 3. æ ¡å‡†ä¸åˆ‡ç‰‡
        diff = (self.white_ref - self.dark_ref)
        diff[diff == 0] = 1e-6

        raw_sel = raw_img[:, :, self.selected_bands]
        dark_sel = self.dark_ref[self.selected_bands]
        diff_sel = diff[self.selected_bands]

        reflectance = (raw_sel - dark_sel) / diff_sel

        # 4. äº®åº¦è¿‡æ»¤
        mean_intensity = np.mean(reflectance, axis=2)
        valid_mask = mean_intensity > brightness_thresh

        pet_pixels = 0
        inf_time = 0

        if np.sum(valid_mask) > 0:
            valid_pixels = reflectance[valid_mask]

            # å½’ä¸€åŒ–
            p_min = np.min(valid_pixels, axis=1, keepdims=True)
            p_max = np.max(valid_pixels, axis=1, keepdims=True)
            denom = p_max - p_min
            denom[denom < 1e-6] = 1.0

            model_input = (valid_pixels - p_min) / denom

            # æ¨ç†
            t0 = time.time()
            preds = self._internal_predict(model_input)
            inf_time = time.time() - t0

            # è®¡ç®— PET æ¦‚ç‡ (å‡è®¾ 0=PET, 1=BG åˆ™éœ€åè½¬; è‹¥ç›´æ¥è¾“å‡º PET æ¦‚ç‡åˆ™ä¸éœ€)
            # æ ¹æ®ä½ ä¹‹å‰çš„é€»è¾‘ï¼š prob_pet = 1.0 - preds
            prob_pet = 1.0 - preds

            # === [æ ¸å¿ƒä¿®æ”¹] ç”Ÿæˆçº¯å‡€çƒ­åŠ›å›¾ ===

            # 1. æ‰å¹³åŒ–ä»¥ä¾¿èµ‹å€¼
            probs_flat = prob_pet.flatten()

            # 2. é˜ˆå€¼æ¸…æ´—ï¼šä½äºç½®ä¿¡åº¦çš„ç›´æ¥è®¾ä¸º 0 (å¯¹åº” Jet é‡Œçš„æ·±è“)
            # è¿™æ ·èƒŒæ™¯å™ªå£°å°±ä¼šå½»åº•æ¶ˆå¤±ï¼Œå˜æˆçº¯è‰²
            probs_flat[probs_flat < conf_thresh] = 0

            # 3. ç»Ÿè®¡åƒç´ 
            pet_pixels = np.sum(probs_flat > 0)

            # 4. èµ‹å€¼å›ç”»å¸ƒ
            heatmap_canvas[valid_mask] = probs_flat

        # 5. ç”Ÿæˆç»“æœå›¾ (çº¯ç²¹çš„ Colormapï¼Œä¸å åŠ åŸå›¾)
        # å°† 0.0-1.0 æ˜ å°„åˆ° 0-255
        heatmap_uint8 = (heatmap_canvas * 255).astype(np.uint8)

        # åº”ç”¨ JET é¢œè‰²æ˜ å°„
        # 0 -> çº¯è“ (èƒŒæ™¯)
        # 128 -> ç»¿/é»„ (ä¸­ç­‰ç½®ä¿¡åº¦)
        # 255 -> çº¯çº¢ (é«˜ç½®ä¿¡åº¦)
        result_bgr = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)

        # è½¬ä¸º RGB ä¾› GUI æ˜¾ç¤º
        result_rgb_out = cv2.cvtColor(result_bgr, cv2.COLOR_BGR2RGB)

        # ä¸ºäº†å…¼å®¹æ¥å£ï¼Œraw_rgb è¿”å›ä¸€ä¸ªç©ºçš„æˆ–è€…ç®€å•çš„å›¾å³å¯ï¼Œå› ä¸º GUI å·²ç»ä¸æ˜¾ç¤ºå®ƒäº†
        # ä½†ä¸ºäº†é¿å…æŠ¥é”™ï¼Œè¿˜æ˜¯ç”Ÿæˆä¸€ä¸‹
        raw_rgb_dummy = np.zeros_like(result_rgb_out)

        info = {
            "inf_time": inf_time,
            "total_time": time.time() - t_start,
            "filename": os.path.basename(input_path),
            "pet_pixels": int(pet_pixels),
            "model_type": self.model_type
        }

        return raw_rgb_dummy, result_rgb_out, info


# ================= æµ‹è¯• =================
if __name__ == "__main__":
    pass