import numpy as np
import os
import random
import spectral.io.envi as envi
import cv2
import json
import gc
import tensorflow as tf

# ================= ğŸš€ 1. æ ¸å¿ƒä¾èµ–æ£€æŸ¥ =================
try:
    from entropy_utils import precompute_entropies, precompute_mutual_information
    from agent import BandSelectionAgent
    from reward_utils import calculate_reward
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–æ–‡ä»¶: {e}")
    print("è¯·ç¡®ä¿ agent.py, entropy_utils.py, reward_utils.py éƒ½åœ¨åŒä¸€ç›®å½•ä¸‹ã€‚")

# ================= ğŸš€ 2. è·¯å¾„ä¸å‚æ•°è®¾ç½® =================
# å…‰è°±æ•°æ®è·¯å¾„
SPE_ROOT = r"L:\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\train-PET"
# æ ‡æ³¨æ–‡ä»¶è·¯å¾„ (åœ¨å­ç›®å½•ä¸­)
JSON_ROOT = r"L:\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\train-PET\fake_images"
# é»‘ç™½æ ¡å‡†æ–‡ä»¶
WHITE_REF_HDR = r"L:\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\DWA\white_ref.hdr"
DARK_REF_HDR = r"L:\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\DWA\black_ref.hdr"

# è®­ç»ƒå‚æ•°
NUM_BANDS_TO_SELECT = 30  # æœ€ç»ˆé€‰å‡ºå¤šå°‘ä¸ªæ³¢æ®µ
TOTAL_EPISODES = 300  # è®­ç»ƒè½®æ•°
SAMPLE_PIXELS_PER_IMAGE = 200  # æ¯å¼ å›¾æå–å¤šå°‘ä¸ªåƒç´ ç‚¹ (é˜²å†…å­˜æº¢å‡º)
MAX_TOTAL_SAMPLES = 15000  # æ€»å…±ç”¨äºè®­ç»ƒçš„åƒç´ ç‚¹ä¸Šé™
ALPHA = 0.7  # å¥–åŠ±å‡½æ•°æƒé‡


# =======================================================

def fix_header_byte_order(hdr_path):
    """è‡ªåŠ¨ä¿®å¤ ENVI å¤´æ–‡ä»¶"""
    if not os.path.exists(hdr_path): return
    try:
        with open(hdr_path, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
        if not any('byte order' in line.lower() for line in lines):
            with open(hdr_path, 'a') as f: f.write('\nbyte order = 0')
    except:
        pass


def load_calib_hdr(hdr_path):
    """åŠ è½½æ ¡å‡†æ–‡ä»¶"""
    fix_header_byte_order(hdr_path)
    # è‡ªåŠ¨æ¨æ–­å¯¹åº”çš„ .spe æ–‡ä»¶è·¯å¾„
    spe_path = hdr_path.replace('.hdr', '.spe')
    if not os.path.exists(spe_path):
        spe_path = os.path.splitext(hdr_path)[0] + ".spe"

    img = envi.open(hdr_path, spe_path).load()
    # ç»Ÿä¸€æ ¼å¼ä¸º (H, W, Bands)
    if img.shape[1] == 208:
        img = np.transpose(img, (0, 2, 1))
    return np.array(img, dtype=np.float32)


def get_mask_from_json(json_path, img_shape):
    """ä» JSON è§£ææ ‡ç­¾"""
    if not os.path.exists(json_path): return None
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        mask = np.zeros(img_shape, dtype=np.uint8)
        found = False
        for shape in data['shapes']:
            lbl = shape['label'].lower()
            pts = np.array(shape['points'], dtype=np.int32)
            # å…¼å®¹ä¸åŒæ ‡ç­¾å
            if 'no_pet' in lbl or 'background' in lbl:
                cv2.fillPoly(mask, [pts], 2)  # è´Ÿæ ·æœ¬
                found = True
            elif 'pet' in lbl:
                cv2.fillPoly(mask, [pts], 1)  # æ­£æ ·æœ¬
                found = True
        return mask if found else None
    except:
        return None


def prepare_drl_data():
    """
    å…¨è‡ªåŠ¨æµç¨‹æ ¸å¿ƒï¼š
    1. æ‰«æç£ç›˜ -> 2. è¯»å–å†…å­˜ -> 3. æå–ç‰¹å¾ -> 4. é‡Šæ”¾åŸå§‹å¤§å›¾ -> 5. è¿”å›è®­ç»ƒé›†
    """
    print("ğŸ“¥ [å…¨è‡ªåŠ¨æ¨¡å¼] å¼€å§‹æ‰«æå¹¶å¤„ç†æ•°æ®...")

    # 1. å‡†å¤‡æ ¡å‡†æ•°æ®
    try:
        white = load_calib_hdr(WHITE_REF_HDR)
        dark = load_calib_hdr(DARK_REF_HDR)
        denom = (white - dark)
        denom[denom == 0] = 1e-6
    except Exception as e:
        raise FileNotFoundError(f"æ ¡å‡†æ–‡ä»¶è¯»å–å¤±è´¥: {e}")

    X_list, y_list = [], []

    # 2. æ‰«ææ–‡ä»¶
    all_files = os.listdir(SPE_ROOT)
    spe_files = [f for f in all_files if f.lower().endswith('.spe')]
    print(f"ğŸ” å‘ç° {len(spe_files)} ä¸ªå…‰è°±æ–‡ä»¶ï¼Œå¼€å§‹å†…å­˜å¤„ç†...")

    for fname in spe_files:
        # å¦‚æœæ ·æœ¬å¤Ÿäº†å°±åœæ­¢ï¼ŒèŠ‚çœæ—¶é—´
        if len(X_list) * (SAMPLE_PIXELS_PER_IMAGE // 2) > MAX_TOTAL_SAMPLES:
            break

        # è·¯å¾„æ„å»º
        base_name = os.path.splitext(fname)[0]
        spe_path = os.path.join(SPE_ROOT, fname)
        hdr_path = os.path.join(SPE_ROOT, base_name + ".hdr")
        json_path = os.path.join(JSON_ROOT, base_name + ".json")

        if not os.path.exists(hdr_path) or not os.path.exists(json_path):
            continue

        try:
            # 3. åŠ è½½ä¸æ ¡å‡†
            fix_header_byte_order(hdr_path)
            raw = envi.open(hdr_path, spe_path).load()
            if raw.shape[1] == 208:
                raw = np.transpose(raw, (0, 2, 1))

            calib = (raw.astype(np.float32) - dark) / denom
            mask = get_mask_from_json(json_path, (calib.shape[0], calib.shape[1]))

            if mask is None: continue

            # 4. æå–ç‰¹å¾åƒç´  (é¿å…æŠŠæ•´å¼ å›¾å­˜å…¥å†…å­˜)
            current_X, current_y = [], []
            for m_val, target in [(1, 1), (2, 0)]:
                idx = np.where(mask == m_val)
                if len(idx[0]) > 0:
                    size = min(len(idx[0]), SAMPLE_PIXELS_PER_IMAGE // 2)
                    s_idx = np.random.choice(len(idx[0]), size=size, replace=False)
                    current_X.append(calib[idx[0][s_idx], idx[1][s_idx], :])
                    current_y.append(np.full(size, target))

            if current_X:
                X_list.append(np.concatenate(current_X))
                y_list.append(np.concatenate(current_y))
                print(f"  + å·²æå–: {fname}", end='\r')

            # 5. ç«‹å³é‡Šæ”¾å¤§å›¾å†…å­˜
            del raw, calib, mask
            gc.collect()

        except Exception as e:
            print(f"\nâŒ å¤„ç†å‡ºé”™ {fname}: {e}")

    if not X_list:
        raise ValueError("æœªèƒ½æå–åˆ°æ•°æ®ï¼è¯·æ£€æŸ¥è·¯å¾„æˆ– JSON æ ‡ç­¾ã€‚")

    print(f"\nâœ… æ•°æ®é›†æ„å»ºå®Œæˆï¼æ€»æ ·æœ¬æ•°: {sum(len(x) for x in X_list)}")
    return np.concatenate(X_list), np.concatenate(y_list)


def start_training():
    # === é˜¶æ®µ 1: æ•°æ®å‡†å¤‡ (å†…å­˜ç›´é€š) ===
    X_train, y_train = prepare_drl_data()
    num_bands = X_train.shape[1]

    # === é˜¶æ®µ 2: é¢„è®¡ç®—æŒ‡æ ‡ ===
    print("ğŸ§  æ­£åœ¨è®¡ç®—ç†µä¸äº’ä¿¡æ¯ (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")
    all_entropies = precompute_entropies(X_train)
    all_mi_scores = precompute_mutual_information(X_train, y_train)

    # === é˜¶æ®µ 3: åˆå§‹åŒ– Agent ===
    agent = BandSelectionAgent(num_bands)

    print(f"\nğŸš€ DRL è®­ç»ƒå¯åŠ¨ | ç›®æ ‡: æŒ‘é€‰ {NUM_BANDS_TO_SELECT} ä¸ªæ³¢æ®µ")
    best_bands = []
    best_reward = -float('inf')

    # === é˜¶æ®µ 4: å¾ªç¯è®­ç»ƒ ===
    for e in range(TOTAL_EPISODES):
        state = np.zeros(num_bands)
        selected = []
        total_r = 0

        for _ in range(NUM_BANDS_TO_SELECT):
            action = agent.get_action(state, selected)
            reward = calculate_reward(selected, action, all_entropies, all_mi_scores, alpha=ALPHA)

            next_state = state.copy()
            next_state[action] = 1
            done = (len(selected) == NUM_BANDS_TO_SELECT - 1)

            agent.remember(state, action, reward, next_state, done)
            agent.train()

            state = next_state
            selected.append(action)
            total_r += reward

        agent.update_target_network()
        # Epsilon è¡°å‡
        if agent.epsilon > agent.epsilon_min:
            agent.epsilon *= agent.epsilon_decay

        # è®°å½•æœ€ä½³ç»“æœ
        if total_r > best_reward:
            best_reward = total_r
            best_bands = sorted(selected)

        if (e + 1) % 10 == 0:
            print(f"Episode: {e + 1}/{TOTAL_EPISODES}, Reward: {total_r:.4f}, Epsilon: {agent.epsilon:.2f}")

    print("\n" + "=" * 50)
    print("ğŸ† æœ€ä¼˜æ³¢æ®µç»„åˆ (å¯ä»¥ç›´æ¥ç”¨äº C++):")
    print(best_bands)
    print("=" * 50)


if __name__ == "__main__":
    # GPU æ˜¾å­˜åŠ¨æ€åˆ†é…
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
        except:
            pass

    start_training()