import numpy as np
import os
import spectral.io.envi as envi
import cv2
import json
import gc
import tensorflow as tf  # âœ… ä¿®å¤ï¼šå¿…é¡»å¯¼å…¥ tensorflow

# ================= ğŸš€ è·¯å¾„å‚æ•°è®¾ç½® =================
# ç¡®ä¿è¿™äº›å˜é‡ååœ¨ä¸‹æ–¹å‡½æ•°è°ƒç”¨æ—¶ä¿æŒä¸€è‡´
SPE_ROOT = r"L:\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\train-PET"
JSON_ROOT = r"L:\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\train-PET\fake_images"
WHITE_REF_HDR = r"L:\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\DWA\white_ref.hdr"
DARK_REF_HDR = r"L:\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\DWA\black_ref.hdr"


# ================================================
def load_raw_calibration(file_path):
    """
    è¯»å–é«˜å…‰è°±ç›¸æœºçš„æ ¡å‡†æ–‡ä»¶ (.wcor æˆ– .dcor)
    å‡è®¾æ ¡å‡†æ•°æ®æ˜¯ 1D æ•°ç»„ï¼ˆæ³¢æ®µå¹³å‡å€¼ï¼‰æˆ–ä¸å›¾åƒå®½åº¦ä¸€è‡´çš„ 2D æ•°ç»„
    """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ ¡å‡†æ–‡ä»¶: {file_path}")

    # æ ¹æ®ä½ ç›¸æœºçš„å…·ä½“æ ¼å¼è¯»å–ï¼Œé€šå¸¸æ˜¯ float32 çš„äºŒè¿›åˆ¶æµ
    # å¦‚æœä½ çš„æ ¡å‡†æ–‡ä»¶æ˜¯ 2048 ä¸ª float32 æ•°å€¼ï¼ˆå¯¹åº”æ³¢æ®µï¼‰ï¼š
    try:
        data = np.fromfile(file_path, dtype=np.float32)
        return data
    except Exception as e:
        raise Exception(f"è¯»å–æ ¡å‡†æ–‡ä»¶å¤±è´¥: {e}")
def fix_header_byte_order(hdr_path):
    if not os.path.exists(hdr_path): return
    try:
        with open(hdr_path, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
        if not any('byte order' in line.lower() for line in lines):
            with open(hdr_path, 'a') as f: f.write('\nbyte order = 0')
    except:
        pass


def load_calib_hdr(hdr_path):
    fix_header_byte_order(hdr_path)
    spe_path = hdr_path.replace('.hdr', '.spe')
    if not os.path.exists(spe_path):
        spe_path = os.path.splitext(hdr_path)[0] + ".spe"
    img = envi.open(hdr_path, spe_path).load()
    if img.shape[1] == 208:
        img = np.transpose(img, (0, 2, 1))
    return np.array(img, dtype=np.float32)

# åœ¨ data_preprocessing.py ä¸­æ·»åŠ  SNV å‡½æ•°
def apply_snv(spectra):
    """
    Standard Normal Variate (SNV) transformation
    è®ºæ–‡å»ºè®®çš„é¢„å¤„ç†æ–¹æ³•ï¼Œæ¶ˆé™¤æ•£å°„æ•ˆåº”
    spectra shape: (n_samples, n_bands)
    """
    mean = np.mean(spectra, axis=1, keepdims=True)
    std = np.std(spectra, axis=1, keepdims=True)
    # é¿å…é™¤ä»¥0
    std[std == 0] = 1e-6
    return (spectra - mean) / std


def get_mask_from_json(json_path, img_shape):
    if not os.path.exists(json_path): return None
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        mask = np.zeros(img_shape, dtype=np.uint8)
        found = False
        for shape in data['shapes']:
            lbl = shape['label'].lower()
            pts = np.array(shape['points'], dtype=np.int32)
            if 'no_pet' in lbl or 'background' in lbl:
                cv2.fillPoly(mask, [pts], 2)
                found = True
            elif 'pet' in lbl:
                cv2.fillPoly(mask, [pts], 1)
                found = True
        return mask if found else None
    except:
        return None


def load_and_preprocess_data(data_dir, white_path, dark_path, limit_files=2):
    """éªŒè¯æ•°æ®åŠ è½½æ˜¯å¦æ­£å¸¸çš„æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª æ­£åœ¨å¯åŠ¨æ•°æ®é¢„å¤„ç†æµ‹è¯•...")

    try:
        white = load_calib_hdr(white_path)
        dark = load_calib_hdr(dark_path)
        denom = (white - dark)
        denom[denom == 0] = 1e-6

        all_files = os.listdir(data_dir)
        spe_files = [f for f in all_files if f.lower().endswith('.spe')][:limit_files]

        for fname in spe_files:
            base = os.path.splitext(fname)[0]
            spe_path = os.path.join(data_dir, fname)
            hdr_path = os.path.join(data_dir, base + ".hdr")
            json_path = os.path.join(JSON_ROOT, base + ".json")

            if not os.path.exists(json_path):
                print(f"âš ï¸ æ‰¾ä¸åˆ° JSON: {base}.json")
                continue

            raw = envi.open(hdr_path, spe_path).load()
            if raw.shape[1] == 208: raw = np.transpose(raw, (0, 2, 1))
            calib = (raw.astype(np.float32) - dark) / denom
            mask = get_mask_from_json(json_path, (calib.shape[0], calib.shape[1]))

            if mask is not None:
                print(f"âœ… æˆåŠŸåŠ è½½æ–‡ä»¶å¹¶ç”Ÿæˆ Mask: {fname}")
                return calib, mask  # ä»…è¿”å›ç¬¬ä¸€ç»„ç”¨äºæµ‹è¯•éªŒè¯

    except Exception as e:
        print(f"âŒ é¢„å¤„ç†å¤±è´¥: {e}")
    return None, None


if __name__ == "__main__":
    # é…ç½® GPU
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print("ğŸš€ GPU é…ç½®æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ GPU é…ç½®æŠ¥é”™: {e}")

    # --- ğŸ›  ä¿®å¤ä½ç½®ï¼šç¡®ä¿å˜é‡åä¸é¡¶éƒ¨å®šä¹‰å®Œå…¨ä¸€è‡´ ---
    s_data, c_data = load_and_preprocess_data(
        SPE_ROOT,
        WHITE_REF_HDR,
        DARK_REF_HDR,
        limit_files=2
    )

    if s_data is not None:
        print(f"\nâœ¨ æµ‹è¯•é€šè¿‡ï¼")
        print(f"å…‰è°±æ•°æ®å½¢çŠ¶: {s_data.shape}")
        print(f"æ ‡ç­¾æ•°æ®å½¢çŠ¶: {c_data.shape}")
    else:
        print("\nâŒ æœªèƒ½æˆåŠŸæå–æ•°æ®ï¼Œè¯·æ£€æŸ¥è·¯å¾„æˆ–æ–‡ä»¶åã€‚")