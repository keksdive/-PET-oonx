import numpy as np
import os
import json
import tensorflow as tf
import time
import glob
import gc

# å¼•ç”¨ç°æœ‰æ¨¡å—
from entropy_utils import precompute_entropies, precompute_mutual_information
from agent import BandSelectionAgent
from reward_utils import calculate_reward

# å¦‚æœä½ æ²¡æœ‰ visualization æ¨¡å—ï¼Œå¯ä»¥æ³¨é‡Šæ‰ä¸‹é¢è¿™è¡Œ
try:
    from visualization import visualize_spectral_selection
except ImportError:
    visualize_spectral_selection = None

# ================= ğŸ”§ é…ç½®åŒºåŸŸ =================
# æ•°æ®è·¯å¾„ (æŒ‡å‘ save_data.py è¾“å‡ºçš„æ–‡ä»¶å¤¹)
DATA_DIR = r"E:\SPEDATA\NP_data"  # è¯·ç¡®ä¿è·¯å¾„æ­£ç¡®

# ç»“æœä¿å­˜é…ç½®
CONFIG_OUTPUT_FILE = "best_bands_config.json"
MODEL_CHECKPOINT_DIR = "checkpoints"

# DRL è¶…å‚æ•°
NUM_BANDS_TO_SELECT = 30  # æ¯ç§æè´¨é€‰å¤šå°‘ä¸ªæ³¢æ®µ
TOTAL_EPISODES = 300  # æ¯ç§æè´¨è®­ç»ƒå¤šå°‘è½® (å»ºè®® 300-500)
SAMPLE_SIZE = 12000  # é‡‡æ ·æ€»ç‚¹æ•°
ALPHA = 0.7  # å¥–åŠ±æƒé‡

# æ˜¾å­˜é…ç½®
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        tf.config.experimental.set_memory_growth(gpus[0], True)
        print("âœ… GPU æ˜¾å­˜æŒ‰éœ€åˆ†é…å·²å¯ç”¨")
    except RuntimeError as e:
        print(e)


# ================= ğŸ§  å¢å¼ºç‰ˆæ•°æ®åŠ è½½ =================

def load_multiclass_data(data_dir, total_samples=10000):
    """
    åŠ è½½æ•°æ®å¹¶è¿”å›åŸå§‹å¤šç±»åˆ«æ ‡ç­¾ã€‚
    0: Background/Other
    1: PET
    2: CC
    3: PA
    """
    print(f"ğŸš€ [IO] æ­£åœ¨ä» {data_dir} åŠ è½½å¤šæè´¨æ•°æ®...")

    if not os.path.exists(data_dir):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ•°æ®ç›®å½•: {data_dir}")

    all_files = glob.glob(os.path.join(data_dir, "**", "*.npy"), recursive=True)

    # å®šä¹‰ç±»åˆ«æ˜ å°„
    # ç¡®ä¿ save_data.py ç”Ÿæˆçš„æ–‡ä»¶å¤¹åç§°åŒ…å«è¿™äº›å…³é”®å­—
    class_map = {
        "PET": 1,
        "CC": 2,
        "PA": 3
    }

    file_groups = {0: [], 1: [], 2: [], 3: []}

    for f in all_files:
        path_upper = os.path.dirname(f).upper()
        label = 0  # é»˜è®¤ä¸ºèƒŒæ™¯/å…¶ä»–
        for key, val in class_map.items():
            if key in path_upper:
                label = val
                break
        file_groups[label].append(f)

    print(
        f"   ğŸ“Š æ–‡ä»¶åˆ†å¸ƒ: PET={len(file_groups[1])}, CC={len(file_groups[2])}, PA={len(file_groups[3])}, Other={len(file_groups[0])}")

    # æ¯ç±»é‡‡æ ·æ•°é‡ (å°½é‡å¹³è¡¡)
    target_per_class = total_samples // 4

    X_list = []
    y_list = []

    def sample_category(file_list, label, count):
        if not file_list: return
        collected_x = []
        current_count = 0
        np.random.shuffle(file_list)

        for f in file_list:
            if current_count >= count: break
            try:
                data = np.load(f)
                flat = data.reshape(-1, data.shape[2])

                # ç®€å•çš„èƒŒæ™¯è¿‡æ»¤ (å»é™¤å…¨é»‘åƒç´ )
                if label != 0:
                    intensity = np.mean(flat, axis=1)
                    flat = flat[intensity > 0.05]

                if len(flat) == 0: continue

                # éšæœºé‡‡æ ·
                take = min(len(flat), 600)
                idx = np.random.choice(len(flat), take, replace=False)
                collected_x.append(flat[idx])
                current_count += take
            except:
                pass

        if collected_x:
            X_part = np.concatenate(collected_x, axis=0)
            if len(X_part) > count: X_part = X_part[:count]
            y_part = np.full(len(X_part), label)
            X_list.append(X_part)
            y_list.append(y_part)

    # æ‰§è¡Œé‡‡æ ·
    for lbl in [1, 2, 3, 0]:
        sample_category(file_groups[lbl], lbl, target_per_class)

    if not X_list:
        raise ValueError("âŒ æœªåŠ è½½åˆ°æ•°æ®ï¼è¯·æ£€æŸ¥è·¯å¾„æˆ– save_data.py æ˜¯å¦æ­£ç¡®è¿è¡Œã€‚")

    X = np.concatenate(X_list, axis=0)
    y = np.concatenate(y_list, axis=0)

    # Shuffle
    idx = np.arange(len(X))
    np.random.shuffle(idx)

    print(f"âœ… æ•°æ®åŠ è½½å®Œæ¯•: Shape {X.shape}, Labels {np.unique(y)}")
    return X[idx], y[idx]


# ================= ğŸ‹ï¸â€â™‚ï¸ ç‹¬ç«‹è®­ç»ƒæµç¨‹ =================

def train_for_target(target_name, target_label_id, X_all, y_all):
    """
    é’ˆå¯¹ç‰¹å®šæè´¨è¿›è¡Œ DRL è®­ç»ƒ
    :param target_name: 'PET', 'CC', or 'PA'
    :param target_label_id: 1, 2, or 3
    :param X_all: æ‰€æœ‰å…‰è°±æ•°æ®
    :param y_all: åŸå§‹æ ‡ç­¾ (0,1,2,3)
    """
    print(f"\n" + "=" * 60)
    print(f"ğŸ¯ å¼€å§‹è®­ç»ƒç›®æ ‡: [{target_name}] (Label {target_label_id} vs Rest)")
    print("=" * 60)

    num_bands = X_all.shape[1]

    # 1. æ„é€  One-vs-Rest äºŒåˆ†ç±»æ ‡ç­¾
    # ç›®æ ‡æè´¨ = 1, å…¶ä»–æ‰€æœ‰æè´¨(åŒ…æ‹¬èƒŒæ™¯) = 0
    y_binary = (y_all == target_label_id).astype(int)

    pos_samples = np.sum(y_binary == 1)
    neg_samples = np.sum(y_binary == 0)
    print(f"   æ ·æœ¬åˆ†å¸ƒ -> æ­£æ ·æœ¬({target_name}): {pos_samples} | è´Ÿæ ·æœ¬(Rest): {neg_samples}")

    if pos_samples < 100:
        print(f"âš ï¸ è­¦å‘Š: {target_name} æ ·æœ¬å¤ªå°‘ï¼Œè®­ç»ƒæ•ˆæœå¯èƒ½ä¸ä½³ï¼")

    # 2. è®¡ç®—é’ˆå¯¹è¯¥ç›®æ ‡çš„äº’ä¿¡æ¯ (å…³é”®æ­¥éª¤!)
    # è¿™ä¼šå‘Šè¯‰ Agent å“ªäº›æ³¢æ®µæœ€èƒ½åŒºåˆ† [ç›®æ ‡] å’Œ [å…¶ä»–]
    print(f"â³ æ­£åœ¨è®¡ç®— {target_name} çš„ä¸“å±äº’ä¿¡æ¯...")
    entropies = precompute_entropies(X_all)  # ç†µæ˜¯é€šç”¨çš„
    mi_scores = precompute_mutual_information(X_all, y_binary)  # äº’ä¿¡æ¯æ˜¯ç‰¹å¼‚çš„

    # å½’ä¸€åŒ–
    if np.max(entropies) != np.min(entropies):
        entropies = (entropies - np.min(entropies)) / (np.max(entropies) - np.min(entropies))
    if np.max(mi_scores) != np.min(mi_scores):
        mi_scores = (mi_scores - np.min(mi_scores)) / (np.max(mi_scores) - np.min(mi_scores))

    # 3. åˆå§‹åŒ–æ–°çš„ Agent
    tf.keras.backend.clear_session()  # æ¸…ç†æ—§å›¾
    agent = BandSelectionAgent(num_bands)

    best_reward = -np.inf
    best_bands = []

    # 4. è®­ç»ƒå¾ªç¯
    start_time = time.time()
    for e in range(TOTAL_EPISODES):
        state = np.zeros(num_bands)
        selected_bands = []
        episode_reward = 0

        for t in range(NUM_BANDS_TO_SELECT):
            action = agent.get_action(state, selected_bands)

            # ä½¿ç”¨é’ˆå¯¹è¯¥ç›®æ ‡çš„ MI è®¡ç®—å¥–åŠ±
            reward = calculate_reward(selected_bands, action, entropies, mi_scores, alpha=ALPHA)

            next_state = state.copy()
            next_state[action] = 1
            done = (len(selected_bands) == NUM_BANDS_TO_SELECT - 1)

            agent.remember(state, action, reward, next_state, done)
            agent.train()

            state = next_state
            selected_bands.append(action)
            episode_reward += reward

            if done:
                agent.update_target_network()
                break

        # è¡°å‡ & è®°å½•
        if agent.epsilon > agent.epsilon_min:
            agent.epsilon *= agent.epsilon_decay

        if episode_reward > best_reward:
            best_reward = episode_reward
            best_bands = sorted(selected_bands)

        if (e + 1) % 50 == 0:
            print(f"   Episode {e + 1}/{TOTAL_EPISODES} | Reward: {episode_reward:.4f} | Best: {best_reward:.4f}")

    print(f"âœ… {target_name} è®­ç»ƒå®Œæˆ! è€—æ—¶: {(time.time() - start_time):.1f}s")
    print(f"ğŸ’ é€‰å‡ºçš„ç‰¹å¾æ³¢æ®µ: {best_bands}")

    # 5. ç”Ÿæˆè¯¥æè´¨çš„å¯è§†åŒ–å›¾ (å¯é€‰)
    if visualize_spectral_selection:
        try:
            visualize_spectral_selection(
                X_all, y_all, best_bands,
                save_path=f"analysis_{target_name}.png"
            )
        except Exception as e:
            print(f"å¯è§†åŒ–è·³è¿‡: {e}")

    return [int(b) for b in best_bands]


# ================= ğŸš€ ä¸»ç¨‹åº =================

if __name__ == "__main__":
    if not os.path.exists(MODEL_CHECKPOINT_DIR):
        os.makedirs(MODEL_CHECKPOINT_DIR)

    # 1. ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®
    X_global, y_global = load_multiclass_data(DATA_DIR, SAMPLE_SIZE)

    results = {}

    # 2. ä¾æ¬¡å¯¹ PET(1), CC(2), PA(3) è¿›è¡Œè®­ç»ƒ
    targets = [
        ("PET", 1),
        ("CC", 2),
        ("PA", 3)
    ]

    for name, label_id in targets:
        # æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦å­˜åœ¨è¯¥æ ‡ç­¾
        if np.sum(y_global == label_id) == 0:
            print(f"âŒ è·³è¿‡ {name}: æ•°æ®é›†ä¸­æ²¡æœ‰ Label {label_id} çš„æ ·æœ¬ï¼")
            results[f"{name}_bands"] = []
            continue

        # æ‰§è¡Œè®­ç»ƒ
        selected = train_for_target(name, label_id, X_global, y_global)
        results[f"{name}_bands"] = selected

        # æ˜¾å­˜æ¸…ç†
        gc.collect()

    # 3. ä¿å­˜æœ€ç»ˆæ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ’¾ æ­£åœ¨ä¿å­˜å¤šæè´¨æ³¢æ®µé…ç½®...")

    # ç»“æ„åŒ–è¾“å‡º
    final_config = {
        "description": "Multi-material characteristic bands selected by DRL",
        "targets": {
            "PET": results.get("PET_bands", []),
            "CC": results.get("CC_bands", []),
            "PA": results.get("PA_bands", [])
        },
        # ä¸ºäº†å…¼å®¹æ—§ä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠæ‰€æœ‰æ³¢æ®µåˆå¹¶å»é‡ä½œä¸º selected_bands
        # æˆ–è€…ä½ å¯ä»¥ä¿®æ”¹åç»­ä»£ç æ¥è¯»å– specific bands
        "all_unique_bands": sorted(list(set(
            results.get("PET_bands", []) +
            results.get("CC_bands", []) +
            results.get("PA_bands", [])
        )))
    }

    with open(CONFIG_OUTPUT_FILE, 'w') as f:
        json.dump(final_config, f, indent=4)

    print(f"âœ… é…ç½®æ–‡ä»¶å·²ä¿å­˜: {os.path.abspath(CONFIG_OUTPUT_FILE)}")
    print(f"   åŒ…å« PET æ³¢æ®µ: {len(final_config['targets']['PET'])} ä¸ª")
    print(f"   åŒ…å« CC  æ³¢æ®µ: {len(final_config['targets']['CC'])} ä¸ª")
    print(f"   åŒ…å« PA  æ³¢æ®µ: {len(final_config['targets']['PA'])} ä¸ª")
    print("=" * 60)