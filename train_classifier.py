import numpy as np
import os
import spectral.io.envi as envi
import cv2
import json
import gc
import tensorflow as tf
from tensorflow.keras import layers, models
import tf2onnx  # éœ€è¦ pip install tf2onnx

# ================= ğŸ”§ 1. éœ€è¦ä½ å¡«å†™çš„å‚æ•° =================
# ã€å…³é”®ã€‘æŠŠ training.py è·‘å‡ºæ¥çš„æœ€ä¼˜æ³¢æ®µåˆ—è¡¨å¡«åœ¨è¿™é‡Œ
# ä¸¾ä¾‹: SELECTED_BANDS = [12, 45, 67, 89, ..., 190]
SELECTED_BANDS = [19, 39, 62, 69, 70, 72, 74, 76, 78, 83, 90, 93, 95, 103, 105, 106, 112, 115, 123, 128, 133, 140, 143, 150, 160, 172, 174, 180, 187, 197]

# è·¯å¾„è®¾ç½® (ä¿æŒä¸å˜)
SPE_ROOT = r"L:\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\train-PET"
JSON_ROOT = r"L:\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\train-PET\fake_images"
WHITE_REF_HDR = r"L:\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\DWA\white_ref.hdr"
DARK_REF_HDR = r"L:\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\12.12æ•°æ®é›†ï¼ˆå•æ’å…‰æºï¼‰\DWA\black_ref.hdr"

# è¾“å‡ºæ¨¡å‹è·¯å¾„
MODEL_SAVE_PATH = "pet_classifier_model"
ONNX_SAVE_PATH = "pet_classifier.onnx"

# è®­ç»ƒå‚æ•°
SAMPLE_PIXELS_PER_IMAGE = 500  # åˆ†ç±»è®­ç»ƒå¯ä»¥å¤šé‡‡ç‚¹æ ·
MAX_TOTAL_SAMPLES = 500000 # æ€»æ ·æœ¬é‡ä¹Ÿå¯ä»¥å¤§ä¸€ç‚¹
BATCH_SIZE = 256
EPOCHS = 300


# =======================================================

def fix_header_byte_order(hdr_path):
    if not os.path.exists(hdr_path): return
    try:
        with open(hdr_path, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
        if not any('byte order' in line.lower() for line in lines):
            with open(hdr_path, 'a') as f: f.write('\nbyte order = 0')
    except:
        pass


def load_calib_hdr(hdr_path):
    fix_header_byte_order(hdr_path)
    spe_path = hdr_path.replace('.hdr', '.spe')
    if not os.path.exists(spe_path):
        spe_path = os.path.splitext(hdr_path)[0] + ".spe"
    img = envi.open(hdr_path, spe_path).load()
    if img.shape[1] == 208: img = np.transpose(img, (0, 2, 1))
    return np.array(img, dtype=np.float32)


def get_mask_from_json(json_path, img_shape):
    if not os.path.exists(json_path): return None
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        mask = np.zeros(img_shape, dtype=np.uint8)
        found = False
        for shape in data['shapes']:
            lbl = shape['label'].lower()
            pts = np.array(shape['points'], dtype=np.int32)
            if 'no_pet' in lbl or 'background' in lbl:
                cv2.fillPoly(mask, [pts], 2)  # Label 0 in training
                found = True
            elif 'pet' in lbl:
                cv2.fillPoly(mask, [pts], 1)  # Label 1 in training
                found = True
        return mask if found else None
    except:
        return None


def prepare_classification_data():
    if not SELECTED_BANDS:
        raise ValueError("âŒ è¯·å…ˆåœ¨ä»£ç é¡¶éƒ¨çš„ SELECTED_BANDS ä¸­å¡«å…¥ DRL é€‰å‡ºçš„æ³¢æ®µç´¢å¼•ï¼")

    print(f"ğŸ“¥ æ­£åœ¨åŠ è½½æ•°æ®ï¼Œä»…ä¿ç•™é€‰å®šçš„ {len(SELECTED_BANDS)} ä¸ªæ³¢æ®µ...")

    white = load_calib_hdr(WHITE_REF_HDR)
    dark = load_calib_hdr(DARK_REF_HDR)
    denom = (white - dark)
    denom[denom == 0] = 1e-6

    # é¢„å…ˆåªæˆªå–ç™½/é»‘å‚è€ƒçš„å¯¹åº”æ³¢æ®µï¼ŒèŠ‚çœè®¡ç®—
    white = white[:, :, SELECTED_BANDS]
    dark = dark[:, :, SELECTED_BANDS]
    denom = denom[:, :, SELECTED_BANDS]

    X_list, y_list = [], []
    all_files = os.listdir(SPE_ROOT)
    spe_files = [f for f in all_files if f.lower().endswith('.spe')]

    for fname in spe_files:
        if len(X_list) * (SAMPLE_PIXELS_PER_IMAGE // 2) > MAX_TOTAL_SAMPLES: break

        base_name = os.path.splitext(fname)[0]
        spe_path = os.path.join(SPE_ROOT, fname)
        hdr_path = os.path.join(SPE_ROOT, base_name + ".hdr")
        json_path = os.path.join(JSON_ROOT, base_name + ".json")

        if not os.path.exists(hdr_path) or not os.path.exists(json_path): continue

        try:
            fix_header_byte_order(hdr_path)
            raw = envi.open(hdr_path, spe_path).load()
            if raw.shape[1] == 208: raw = np.transpose(raw, (0, 2, 1))

            # === å…³é”®æ­¥éª¤ï¼šåªå–é€‰å®šæ³¢æ®µ ===
            raw_selected = raw[:, :, SELECTED_BANDS]

            calib = (raw_selected.astype(np.float32) - dark) / denom
            mask = get_mask_from_json(json_path, (calib.shape[0], calib.shape[1]))

            if mask is None: continue

            current_X, current_y = [], []
            for m_val, target in [(1, 1), (2, 0)]:  # 1=PET, 0=Non-PET
                idx = np.where(mask == m_val)
                if len(idx[0]) > 0:
                    size = min(len(idx[0]), SAMPLE_PIXELS_PER_IMAGE // 2)
                    s_idx = np.random.choice(len(idx[0]), size=size, replace=False)
                    current_X.append(calib[idx[0][s_idx], idx[1][s_idx], :])
                    current_y.append(np.full(size, target))

            if current_X:
                X_list.append(np.concatenate(current_X))
                y_list.append(np.concatenate(current_y))
                print(f"  + å·²å¤„ç†: {fname}", end='\r')

            del raw, raw_selected, calib, mask
            gc.collect()

        except Exception as e:
            print(f"âŒ é”™è¯¯ {fname}: {e}")

    return np.concatenate(X_list), np.concatenate(y_list)


def build_model(input_shape):
    """æ„å»ºä¸€ä¸ªé€‚åˆ C++ éƒ¨ç½²çš„è½»é‡çº§ MLP æ¨¡å‹"""
    model = models.Sequential([
        layers.InputLayer(input_shape=input_shape),
        layers.Dense(64, activation='relu'),
        layers.Dense(32, activation='relu'),
        layers.Dense(1, activation='sigmoid')  # äºŒåˆ†ç±»ï¼šè¾“å‡º 0~1 æ¦‚ç‡
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model


def main():
    # 1. å‡†å¤‡æ•°æ®
    X, y = prepare_classification_data()
    print(f"\nâœ… æ•°æ®å‡†å¤‡å®Œæˆã€‚æ ·æœ¬å½¢: {X.shape}, æ ‡ç­¾å½¢: {y.shape}")

    # 2. æ„å»ºä¸è®­ç»ƒæ¨¡å‹
    print("ğŸš€ å¼€å§‹è®­ç»ƒåˆ†ç±»å™¨...")
    model = build_model(input_shape=(len(SELECTED_BANDS),))

    model.fit(X, y, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2)

    # 3. ä¿å­˜ä¸º H5 (Pythonç”¨)
    model.save(MODEL_SAVE_PATH + ".h5")
    print(f"ğŸ’¾ Keras æ¨¡å‹å·²ä¿å­˜è‡³ {MODEL_SAVE_PATH}.h5")

    # 4. å¯¼å‡ºä¸º ONNX (C++ç”¨)
    print("ğŸ”„ æ­£åœ¨å¯¼å‡ºä¸º ONNX æ ¼å¼...")
    spec = (tf.TensorSpec((None, len(SELECTED_BANDS)), tf.float32, name="input"),)
    model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13)
    with open(ONNX_SAVE_PATH, "wb") as f:
        f.write(model_proto.SerializeToString())

    print("=" * 50)
    print(f"ğŸ† éƒ¨ç½²æ–‡ä»¶å·²ç”Ÿæˆ: {ONNX_SAVE_PATH}")
    print(f"C++ æ¨ç†æ—¶ï¼Œè¯·åªæˆªå–ä»¥ä¸‹ {len(SELECTED_BANDS)} ä¸ªé€šé“:")
    print(SELECTED_BANDS)
    print("=" * 50)


if __name__ == "__main__":
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True)
        except:
            pass
    main()