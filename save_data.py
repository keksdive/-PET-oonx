import os
import numpy as np
import spectral.io.envi as envi
import glob
import json
import cv2
import random

# ================= âš™ï¸ å¤šæºæ•°æ®é›†é…ç½®åŒºåŸŸ =================
DATASETS = [
    # 1. PET æ–‡ä»¶å¤¹
    {
        "spe_dir": r"E:\SPEDATA\é«˜è°±ç›¸æœºæ•°æ®é›†\è®­ç»ƒé›†\ç½®ä¿¡åº¦å¤§äº90%PET",
        "json_dir": None
    },
    # 2. é PET æ–‡ä»¶å¤¹ (CC)
    {
        "spe_dir": r"E:\SPEDATA\é«˜è°±ç›¸æœºæ•°æ®é›†\è®­ç»ƒé›†\no_PET\CC",
        "json_dir": None
    },
    # 3. é PET æ–‡ä»¶å¤¹ (PA)
    {
        "spe_dir": r"E:\SPEDATA\é«˜è°±ç›¸æœºæ•°æ®é›†\è®­ç»ƒé›†\no_PET\PA",
        "json_dir": None
    }
]

# è¾“å‡ºä¿å­˜è·¯å¾„
OUTPUT_DIR = r"E:\SPEDATA\NP_newdata"

# æ ‡ç­¾å®šä¹‰
LABEL_MAP = {
    "PET": 1,
    "CC": 2,
    "PA": 3,
    "PP": 4,
    "OTHER": 5,
    "é†‹é…¸": 2
}

# é‡‡æ ·å‚æ•°
SAMPLES_PER_IMAGE = 3000  # å¢åŠ é‡‡æ ·æ•°ï¼Œå› ä¸ºæˆ‘ä»¬ç°åœ¨ä¸¢å¼ƒäº†èƒŒæ™¯
THRESHOLD_RATIO = 0.15  # ã€ä¸¥æ ¼è¿‡æ»¤ã€‘ä½äºæœ€å¤§äº®åº¦ 15% çš„ç›´æ¥ä¸¢å¼ƒ
TARGET_BANDS = 208  # å¼ºåˆ¶å¯¹é½æ³¢æ®µæ•°


# =======================================================

def repair_hdr_file(hdr_path):
    """è‡ªåŠ¨ä¿®å¤ç¼ºå°‘çš„ byte order"""
    try:
        with open(hdr_path, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
        content = "".join(lines).lower()
        if "byte order" not in content:
            lines.append("\nbyte order = 0\n")
            with open(hdr_path, 'w', encoding='utf-8') as f:
                f.writelines(lines)
    except:
        pass


def load_envi_image(hdr_path):
    """åŠ è½½å¹¶å¯¹é½ ENVI å›¾åƒ"""
    try:
        repair_hdr_file(hdr_path)
        base = os.path.splitext(hdr_path)[0]
        spe_path = base + ".spe"
        if not os.path.exists(spe_path): spe_path = base + ".raw"
        if not os.path.exists(spe_path): return None

        img_obj = envi.open(hdr_path, spe_path)
        img_data = np.array(img_obj.load(), dtype=np.float32)

        # ç»´åº¦ä¿®æ­£ (H, W, B)
        shape = img_data.shape
        if shape[1] < shape[2] and shape[1] in [206, 208]:
            img_data = np.transpose(img_data, (0, 2, 1))

        # æ³¢æ®µå¯¹é½
        H, W, C = img_data.shape
        if TARGET_BANDS is not None and C != TARGET_BANDS:
            flat = img_data.reshape(-1, C)
            flat_resized = cv2.resize(flat, (TARGET_BANDS, H * W), interpolation=cv2.INTER_LINEAR)
            img_data = flat_resized.reshape(H, W, TARGET_BANDS)

        return img_data
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥ {os.path.basename(hdr_path)}: {e}")
        return None


def get_mask_from_json(json_path, image_shape):
    """ä¼˜å…ˆä½¿ç”¨ JSON æ ‡æ³¨ï¼ˆå¦‚æœæœ‰ï¼‰"""
    H, W = image_shape[:2]
    mask = np.zeros((H, W), dtype=np.uint8)
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        for shape in data.get('shapes', []):
            points = np.array(shape['points'], dtype=np.int32)
            cv2.fillPoly(mask, [points], 1)
        return mask.astype(bool)
    except:
        return None


def get_mask_from_threshold(img_data):
    """ã€åŠŸèƒ½1 & 3ã€‘è®¡ç®—å¼ºåº¦å¹¶è¿›è¡Œä¸¥æ ¼é˜ˆå€¼è¿‡æ»¤"""
    # è®¡ç®—å¹³å‡å¼ºåº¦
    intensity = np.mean(img_data, axis=2)
    # åŠ¨æ€é˜ˆå€¼ï¼šæœ€å¤§å¼ºåº¦çš„ 15%
    limit = np.max(intensity) * THRESHOLD_RATIO
    # ç”Ÿæˆæ©è†œï¼šåªæœ‰å¤§äºé˜ˆå€¼çš„æ‰æ˜¯ True
    return intensity > limit


def min_max_normalize(pixels):
    """ã€åŠŸèƒ½2ã€‘Min-Max å½’ä¸€åŒ– (é’ˆå¯¹åƒç´ çº§)"""
    # pixels shape: (N, Bands)
    # axis=1 è¡¨ç¤ºå¯¹æ¯ä¸ªåƒç´ è‡ªèº«çš„æ³¢æ®µè¿›è¡Œå½’ä¸€åŒ–
    p_min = pixels.min(axis=1, keepdims=True)
    p_max = pixels.max(axis=1, keepdims=True)

    # é¿å…é™¤ä»¥0
    range_val = p_max - p_min
    range_val[range_val == 0] = 1e-6

    return (pixels - p_min) / range_val


def determine_label(path_string):
    path_upper = path_string.upper()
    for key in ["CC", "PA", "PP", "é†‹é…¸", "OTHER"]:
        if key in path_upper:
            return LABEL_MAP.get(key, LABEL_MAP.get("OTHER")), key
    if "PET" in path_upper:
        if "NO_PET" in path_upper or "NO-PET" in path_upper:
            return None, None
        return LABEL_MAP["PET"], "PET"
    return None, None


def process_and_save_data():
    if not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)
    all_pixels, all_labels = [], []
    stats = {k: 0 for k in LABEL_MAP.values()}  # ç»Ÿè®¡æ‰€æœ‰æ ‡ç­¾
    total_files = 0

    print(f"ğŸš€ å¼€å§‹å¤„ç† {len(DATASETS)} ä¸ªæ•°æ®æº...")

    for ds_config in DATASETS:
        spe_dir, json_dir = ds_config["spe_dir"], ds_config.get("json_dir")
        if not os.path.exists(spe_dir): continue

        hdr_files = glob.glob(os.path.join(spe_dir, "**", "*.hdr"), recursive=True)
        print(f"ğŸ“‚ æ‰«æ: {spe_dir} ({len(hdr_files)} files)")

        for idx, hdr_path in enumerate(hdr_files):
            if "ref" in os.path.basename(hdr_path).lower(): continue

            full_path_str = hdr_path
            label_id, label_name = determine_label(full_path_str)
            if label_id is None: continue

            img_data = load_envi_image(hdr_path)
            if img_data is None: continue

            # 1. è·å–æœ‰æ•ˆåŒºåŸŸæ©è†œ
            fg_mask = None
            mode = "Threshold"

            # å¦‚æœæœ‰ JSONï¼Œå…ˆå°è¯• JSONï¼Œå†ç”¨é˜ˆå€¼è¿‡æ»¤ JSON é€‰åŒºå†…çš„æ‚è‰²
            if json_dir:
                base = os.path.splitext(os.path.basename(hdr_path))[0]
                jp = os.path.join(json_dir, base + ".json")
                if os.path.exists(jp):
                    json_mask = get_mask_from_json(jp, img_data.shape)
                    if json_mask is not None:
                        # å³ä½¿æœ‰ JSONï¼Œä¹Ÿè¦å†å ä¸€å±‚äº®åº¦è¿‡æ»¤ï¼Œå»æ‰æ ‡æ³¨æ¡†é‡Œçš„é»‘è‰²èƒŒæ™¯
                        thresh_mask = get_mask_from_threshold(img_data)
                        fg_mask = json_mask & thresh_mask
                        mode = "JSON+Threshold"

            # å¦‚æœæ²¡æœ‰ JSONï¼Œç›´æ¥ç”¨é˜ˆå€¼
            if fg_mask is None:
                fg_mask = get_mask_from_threshold(img_data)
                mode = "Auto-Threshold"

            # 2. ã€ä¸¥æ ¼è¿‡æ»¤ã€‘æå–åƒç´ 
            # åªæå– Mask ä¸º True çš„éƒ¨åˆ† (å³ > 15% äº®åº¦çš„éƒ¨åˆ†)
            # ä¸¢å¼ƒæ‰€æœ‰ Mask ä¸º False çš„éƒ¨åˆ† (èƒŒæ™¯)
            valid_pixels = img_data[fg_mask]

            if len(valid_pixels) > 0:
                # éšæœºé‡‡æ ·ï¼Œé˜²æ­¢æ•°æ®é‡è¿‡å¤§
                if len(valid_pixels) > SAMPLES_PER_IMAGE:
                    indices = np.random.choice(len(valid_pixels), SAMPLES_PER_IMAGE, replace=False)
                    valid_pixels = valid_pixels[indices]

                # 3. ã€å½’ä¸€åŒ–ã€‘æ‰§è¡Œ Min-Max å½’ä¸€åŒ–
                # å°†æ•°æ®æ˜ å°„åˆ° 0-1ï¼Œæ¶ˆé™¤å…‰å¼ºå½±å“
                norm_pixels = min_max_normalize(valid_pixels)

                # 4. ä¿å­˜
                all_pixels.append(norm_pixels)
                all_labels.append(np.full(len(norm_pixels), label_id, dtype=np.int32))
                stats[label_id] += len(norm_pixels)

            total_files += 1
            if idx % 20 == 0:
                print(
                    f"   [{idx + 1}] {os.path.basename(hdr_path):<20} | ğŸ·ï¸ {label_name}({label_id}) | âš™ï¸ {mode} | æ ·æœ¬æ•°: {len(valid_pixels)}")

    if not all_pixels:
        print("âŒ æ— æ•°æ®ï¼Œè¯·æ£€æŸ¥è·¯å¾„æˆ–é˜ˆå€¼è®¾ç½®æ˜¯å¦è¿‡é«˜ã€‚")
        return

    print("\nğŸ“¦ åˆå¹¶æ•°æ®...")
    X = np.vstack(all_pixels)
    y = np.concatenate(all_labels)

    # æ‰“ä¹±æ•°æ®
    perm = np.random.permutation(len(y))
    X, y = X[perm], y[perm]

    print("-" * 30)
    print(f"âœ… å®Œæˆ! æ€»æ–‡ä»¶: {total_files}")
    for k, v in stats.items():
        if v > 0: print(f"  Label {k}: {v}")
    print(f"ğŸ“Š æ•°æ®å½¢çŠ¶: X={X.shape}, y={y.shape}")
    print(f"ğŸ“‰ æ•°æ®èŒƒå›´: Min={X.min():.4f}, Max={X.max():.4f} (åº”ä¸º 0~1)")

    np.save(os.path.join(OUTPUT_DIR, "X.npy"), X)
    np.save(os.path.join(OUTPUT_DIR, "y.npy"), y)
    print(f"ğŸ’¾ å·²ä¿å­˜è‡³ {OUTPUT_DIR}")


if __name__ == "__main__":
    process_and_save_data()