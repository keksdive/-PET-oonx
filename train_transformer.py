import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers, callbacks
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import ModelCheckpoint
import os
import time
import datetime

# ================= 1. ç¡¬ä»¶æ£€æŸ¥ä¸é…ç½® =================
gpus = tf.config.list_physical_devices('GPU')
print(f"\n{'=' * 40}")
print(f"ğŸ–¥ï¸ ç¡¬ä»¶æ£€æµ‹ç»“æœ: å‘ç° {len(gpus)} ä¸ª GPU")
if len(gpus) == 0:
    print("âš ï¸ è­¦å‘Š: æœªæ£€æµ‹åˆ° GPUï¼æ¨¡å‹å°†ä½¿ç”¨ CPU è®­ç»ƒï¼Œé€Ÿåº¦ä¼šå˜æ…¢ã€‚")
    print("   -> å·²è‡ªåŠ¨åˆ‡æ¢ä¸º 'è½»é‡çº§ CNN' æ¨¡å‹ä»¥é€‚åº” CPUã€‚")
    USE_TRANSFORMER = False  # æ— æ˜¾å¡æ—¶ï¼Œç¦ç”¨ Transformer
else:
    print(f"âœ… æ˜¾å¡å°±ç»ª: {gpus[0].name}")
    print("   -> å°†ä½¿ç”¨ 'Transformer + CNN' æ··åˆæ¨¡å‹ã€‚")
    USE_TRANSFORMER = True  # æœ‰æ˜¾å¡æ—¶ï¼Œä½¿ç”¨å¼ºåŠ›æ¨¡å‹

    # å¯ç”¨æ··åˆç²¾åº¦åŠ é€Ÿ (ä»…é™ GPU)
    try:
        from tensorflow.keras import mixed_precision

        mixed_precision.set_global_policy('mixed_float16')
        print("âš¡ å·²å¯ç”¨æ··åˆç²¾åº¦ (Mixed Precision) åŠ é€Ÿ")
    except:
        pass
print(f"{'=' * 40}\n")

# ================= ğŸ”§ è·¯å¾„é…ç½® =================
DATA_DIR = r"E:\SPEDATA\NP_newdata"
MODEL_SAVE_DIR = r"D:\DRL\DRL1\models"
if not os.path.exists(MODEL_SAVE_DIR): os.makedirs(MODEL_SAVE_DIR)

# âš¡ æé€Ÿé…ç½®
BATCH_SIZE = 2048  # å¤§æ‰¹é‡
EPOCHS = 100


# ================= 2. æ•°æ®ç®¡é“ä¼˜åŒ– (å…³é”®æé€Ÿç‚¹) =================
def create_dataset(X, y, is_training=True):
    """
    ä½¿ç”¨ tf.data API æ„å»ºé«˜æ€§èƒ½æ•°æ®ç®¡é“
    """
    # 1. åˆ›å»ºæ•°æ®é›†
    dataset = tf.data.Dataset.from_tensor_slices((X, y))

    # 2. è®­ç»ƒé›†æ‰“ä¹±
    if is_training:
        dataset = dataset.shuffle(buffer_size=10000)

    # 3. åˆ†æ‰¹
    dataset = dataset.batch(BATCH_SIZE)

    # 4. ã€æ ¸å¿ƒä¼˜åŒ–ã€‘ç¼“å­˜ä¸é¢„å–
    dataset = dataset.cache()
    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)

    return dataset


# ================= 3. æ¨¡å‹å®šä¹‰ =================
def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):
    x = layers.LayerNormalization(epsilon=1e-6)(inputs)
    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)
    x = layers.Dropout(dropout)(x)
    res = x + inputs
    x = layers.LayerNormalization(epsilon=1e-6)(res)
    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation="relu")(x)
    x = layers.Dropout(dropout)(x)
    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)
    return x + res


def build_model(input_shape, use_transformer=True):
    inputs = layers.Input(shape=input_shape)
    x = layers.Reshape((input_shape[0], 1))(inputs)

    # é€šç”¨ CNN ç‰¹å¾æå–å±‚
    x = layers.Conv1D(32, 5, padding="same", activation="relu")(x)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling1D(2)(x)

    x = layers.Conv1D(64, 3, padding="same", activation="relu")(x)
    x = layers.MaxPooling1D(2)(x)

    if use_transformer:
        # === æ˜¾å¡æ¨¡å¼ï¼šTransformer ===
        x = transformer_encoder(x, 64, 2, 128, 0.1)
        x = layers.GlobalAveragePooling1D()(x)
    else:
        # === CPUæ¨¡å¼ï¼šçº¯ CNN ===
        x = layers.Conv1D(128, 3, padding="same", activation="relu")(x)
        x = layers.GlobalAveragePooling1D()(x)

    x = layers.Dense(64, activation="relu")(x)
    x = layers.Dropout(0.2)(x)
    outputs = layers.Dense(1, activation="sigmoid")(x)

    name = "Transformer_Model" if use_transformer else "Fast_CNN_Model"
    return models.Model(inputs, outputs, name=name)


# ================= 4. è‡ªå®šä¹‰å›è°ƒå‡½æ•° (ç§»åˆ°å…¨å±€èŒƒå›´) =================
class SmartModelCheckpoint(tf.keras.callbacks.Callback):
    def __init__(self, save_dir, min_delta=0.001):
        super(SmartModelCheckpoint, self).__init__()
        self.save_dir = save_dir
        self.min_delta = min_delta
        self.best_acc = -float('inf')

    def on_epoch_end(self, epoch, logs=None):
        current_acc = logs.get('val_accuracy')

        # å¦‚æœå½“å‰ç²¾åº¦ > (å†å²æœ€é«˜ + é—¨æ§›)
        if current_acc is not None and current_acc > (self.best_acc + self.min_delta):
            # 1. å‡†å¤‡æ–‡ä»¶å
            time_str = datetime.datetime.now().strftime("%Y%m%d-%H%M")
            acc_str = f"{current_acc:.4f}"

            # Windows æ–‡ä»¶åä¸å»ºè®®ç”¨â€” (em dash)ï¼Œæ”¹ç”¨æ ‡å‡†æ¨ªæ  -
            filename = f"classic_{time_str}_acc_{acc_str}.h5"
            save_path = os.path.join(self.save_dir, filename)

            # 2. ä¿å­˜æ¨¡å‹
            self.model.save(save_path)
            print(f"\nğŸ’¾ [æ–°çºªå½•] ç²¾åº¦ä» {self.best_acc:.4f} æå‡è‡³ {current_acc:.4f}ï¼Œå·²ä¿å­˜: {filename}")

            # 3. æ›´æ–°æœ€é«˜åˆ†
            self.best_acc = current_acc


# ================= 5. ä¸»æµç¨‹ =================
if __name__ == "__main__":
    print("ğŸš€ æ­£åœ¨åŠ è½½æ•°æ®é›† (X.npy, y.npy)...")
    x_path = os.path.join(DATA_DIR, "X.npy")
    y_path = os.path.join(DATA_DIR, "y.npy")

    if not os.path.exists(x_path):
        print(f"âŒ é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨ {x_path}")
        exit()

    # å¼ºåˆ¶ float32
    X = np.load(x_path).astype(np.float32)
    y = np.load(y_path).astype(np.float32)

    # æ ‡ç­¾äºŒå€¼åŒ–
    y_binary = np.where(y == 1, 1, 0).astype(np.float32)

    print(f"ğŸ“Š æ•°æ®åŠ è½½å®Œæ¯•: {X.shape}, æ­£æ ·æœ¬ç‡: {np.mean(y_binary):.2%}")

    # åˆ’åˆ†æ•°æ®
    X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)

    # æ„å»ºé«˜é€Ÿæ•°æ®ç®¡é“
    print("âš¡ æ„å»º tf.data é«˜é€Ÿæµæ°´çº¿...")
    train_ds = create_dataset(X_train, y_train, is_training=True)
    val_ds = create_dataset(X_test, y_test, is_training=False)

    # æ„å»ºæ¨¡å‹
    model = build_model(input_shape=(X.shape[1],), use_transformer=USE_TRANSFORMER)
    print(f"ğŸ—ï¸ æ¨¡å‹æ¶æ„: {model.name}")

    model.compile(optimizer=optimizers.Adam(1e-4),
                  loss="binary_crossentropy",
                  metrics=["accuracy"])

    # å®ä¾‹åŒ–è‡ªå®šä¹‰å›è°ƒ
    auto_save_callback = SmartModelCheckpoint(
        save_dir=MODEL_SAVE_DIR,
        min_delta=0.0  # åªè¦æœ‰æå‡å°±ä¿å­˜
    )

    print(f"ğŸ”¥ å¼€å§‹è®­ç»ƒ (Batch Size={BATCH_SIZE})...")
    start_time = time.time()

    # è®­ç»ƒ (ä»…ä¸€æ¬¡)
    history = model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=EPOCHS,
        callbacks=[auto_save_callback]
    )

    total_time = time.time() - start_time
    print(f"âœ… è®­ç»ƒå®Œæˆï¼æ€»è€—æ—¶: {total_time / 60:.2f} åˆ†é’Ÿ")

    # å¯¼å‡ºæœ€ç»ˆæ¨¡å‹
    final_path = os.path.join(MODEL_SAVE_DIR, "final_model.h5")
    model.save(final_path)

    # å¯¼å‡º ONNX
    import tf2onnx

    spec = (tf.TensorSpec((None, X.shape[1]), tf.float32, name="input"),)
    model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13)

    onnx_path = os.path.join(MODEL_SAVE_DIR, "pet_classifier.onnx")
    with open(onnx_path, "wb") as f:
        f.write(model_proto.SerializeToString())
    print(f"ğŸ† ONNX å¯¼å‡ºå®Œæˆ: {onnx_path}")