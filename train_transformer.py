import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers, callbacks
import os
import json
import glob
import random

# ================= ğŸ”§ é…ç½® =================
CONFIG_FILE = "best_bands_config.json"
DATA_ROOT = r"I:\SPEDATA\NP_data"  # æŒ‡å‘ save_data.py çš„è¾“å‡º
MODEL_SAVE_PATH = r"D:\DRL\DRL1\final_model.h5"

BATCH_SIZE = 64
EPOCHS = 50
PIXELS_PER_FILE = 500  # æ¯æ¬¡ä»ä¸€ä¸ªæ–‡ä»¶é‡Œå–å¤šå°‘ä¸ªåƒç´ å‚ä¸è®­ç»ƒ

# ç±»åˆ«æ˜ å°„ (å¿…é¡»ä¸ save_data.py çš„æ–‡ä»¶å¤¹ä¸€è‡´)
CLASS_MAP = {"Background": 0, "PET": 1, "CC": 2, "PA": 3, "PP": 4, "OTHER": 5}
NUM_CLASSES = len(CLASS_MAP)


# ================= ğŸ§  æ•°æ®ç”Ÿæˆå™¨ =================
class SpectralDataGenerator(tf.keras.utils.Sequence):
    def __init__(self, file_list, selected_bands, batch_size=64, samples_per_file=500):
        self.file_list = file_list
        self.selected_bands = selected_bands
        self.batch_size = batch_size
        self.samples_per_file = samples_per_file
        self.indexes = np.arange(len(self.file_list))
        self.on_epoch_end()

    def __len__(self):
        # ä¼°ç®—æ¯ä¸ª Epoch çš„æ­¥æ•°
        return int(len(self.file_list) * 2)  # è¿™é‡Œçš„ç³»æ•°å¯è°ƒ

    def on_epoch_end(self):
        np.random.shuffle(self.indexes)

    def __getitem__(self, index):
        # åŠ¨æ€ç”Ÿæˆä¸€ä¸ª Batch çš„æ•°æ®
        batch_X, batch_y = [], []

        while len(batch_X) < self.batch_size:
            # éšæœºé€‰ä¸€ä¸ªæ–‡ä»¶
            file_idx = np.random.choice(len(self.file_list))
            file_path = self.file_list[file_idx]

            # 1. ç¡®å®š Label
            folder_name = os.path.basename(os.path.dirname(file_path))
            label_id = CLASS_MAP.get(folder_name, 5)  # é»˜è®¤ OTHER

            # 2. åŠ è½½æ•°æ®
            try:
                img = np.load(file_path).astype(np.float32)  # (H, W, Bands)
            except:
                continue

            # 3. ç­›é€‰æ³¢æ®µ
            if self.selected_bands:
                img = img[:, :, self.selected_bands]

            # 4. ç®€å•çš„é˜ˆå€¼æ©è†œ (åŒºåˆ†èƒŒæ™¯å’Œå‰æ™¯)
            # å‡è®¾å–ä¸­é—´å‡ ä¸ªæ³¢æ®µçš„å¹³å‡å€¼
            intensity = np.mean(img, axis=2)
            thresh = np.max(intensity) * 0.15

            fg_mask = intensity > thresh
            bg_mask = ~fg_mask

            # 5. é‡‡æ · (å‰æ™¯ & èƒŒæ™¯)
            # é‡‡æ ·å‰æ™¯ (Label = label_id)
            fg_pixels = img[fg_mask]
            if len(fg_pixels) > 0:
                take = min(len(fg_pixels), self.samples_per_file // 2)
                chosen = fg_pixels[np.random.choice(len(fg_pixels), take)]
                batch_X.append(chosen)
                batch_y.append(np.full(take, label_id))

            # é‡‡æ ·èƒŒæ™¯ (Label = 0)
            bg_pixels = img[bg_mask]
            if len(bg_pixels) > 0:
                take = min(len(bg_pixels), self.samples_per_file // 2)
                chosen = bg_pixels[np.random.choice(len(bg_pixels), take)]
                batch_X.append(chosen)
                batch_y.append(np.full(take, 0))  # èƒŒæ™¯ Label 0

        # æ•´ç† Batch
        X_out = np.vstack(batch_X)
        y_out = np.concatenate(batch_y)

        # æˆªå–ç²¾ç¡®çš„ Batch Size (æˆ–è€…å¤§ä¸€ç‚¹ä¹Ÿå¯ä»¥)
        indices = np.random.choice(len(X_out), self.batch_size)
        return X_out[indices], y_out[indices]


# ================= ğŸš€ ä¸»ç¨‹åº =================
def build_model(input_dim, num_classes):
    model = models.Sequential([
        layers.Input(shape=(input_dim,)),
        layers.Reshape((input_dim, 1)),
        layers.Conv1D(32, 5, activation='relu', padding='same'),
        layers.MaxPooling1D(2),
        layers.Conv1D(64, 3, activation='relu', padding='same'),
        layers.GlobalAveragePooling1D(),
        layers.Dense(64, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(num_classes, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model


if __name__ == "__main__":
    # 1. åŠ è½½æ³¢æ®µé…ç½®
    with open(CONFIG_FILE, 'r') as f:
        config = json.load(f)
        bands = config["selected_bands"]
    print(f"ğŸ¤– ä½¿ç”¨æ³¢æ®µ: {bands}")

    # 2. æ‰«ææ‰€æœ‰ .npy æ–‡ä»¶
    all_files = glob.glob(os.path.join(DATA_ROOT, "**", "*.npy"), recursive=True)
    random.shuffle(all_files)

    # åˆ’åˆ†è®­ç»ƒ/éªŒè¯ (æŒ‰æ–‡ä»¶åˆ’åˆ†)
    split = int(len(all_files) * 0.8)
    train_files = all_files[:split]
    val_files = all_files[split:]

    print(f"ğŸ“‚ å‘ç° {len(all_files)} ä¸ªæ–‡ä»¶. Train: {len(train_files)}, Val: {len(val_files)}")

    # 3. åˆ›å»ºç”Ÿæˆå™¨
    train_gen = SpectralDataGenerator(train_files, bands, batch_size=BATCH_SIZE)
    val_gen = SpectralDataGenerator(val_files, bands, batch_size=BATCH_SIZE)

    # 4. è®­ç»ƒ
    model = build_model(len(bands), NUM_CLASSES)
    model.fit(
        train_gen,
        validation_data=val_gen,
        epochs=EPOCHS,
        callbacks=[
            callbacks.ModelCheckpoint(MODEL_SAVE_PATH, save_best_only=True),
            callbacks.EarlyStopping(patience=5)
        ]
    )
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {MODEL_SAVE_PATH}")