import numpy as np
import matplotlib.pyplot as plt
import spectral.io.envi as envi
import os
import time
import glob
import json
import cv2
from scipy.signal import savgol_filter
import tensorflow as tf
from tensorflow.keras import layers

# ================= ğŸ”§ é…ç½®åŒºåŸŸ =================
# [1] æ¨¡å‹è·¯å¾„
MODEL_PATH = r"J:\å¤šé…šç±»\final_cascade_model\cascade_model.h5"

# [2] é…ç½®æ–‡ä»¶
CONFIG_PATH = r"J:\å¤šé…šç±»\json-procession-result\material_specific_features.json"

# [3] è¾“å…¥/è¾“å‡ºè·¯å¾„
INPUT_DIR = r"E:\SPEDATA\é«˜è°±ç›¸æœºæ•°æ®é›†\æµ‹è¯•é›†\PET"
OUTPUT_DIR = r"D:\Processed_Result\inference_overlay\123456"  # ç»“æœä¿å­˜è‡³æ–°æ–‡ä»¶å¤¹

# [4] æ ¡å‡†æ–‡ä»¶
WHITE_REF = r"E:\SPEDATA\é«˜è°±ç›¸æœºæ•°æ®é›†\DWA\white_ref.spe"
DARK_REF = r"E:\SPEDATA\é«˜è°±ç›¸æœºæ•°æ®é›†\DWA\dark_ref.spe"

# [5] é˜ˆå€¼ä¸æ˜¾ç¤ºå‚æ•°
BRIGHTNESS_THRESHOLD = 0.15  # äº®åº¦ä¸‹é™ (èƒŒæ™¯)
MAX_BRIGHTNESS_THRESHOLD = 2.00  # äº®åº¦ä¸Šé™ (é«˜å…‰)
# ä¿®æ”¹ä¸º 0.0ï¼Œè¿™æ ·æ‰€æœ‰ç»“æœéƒ½ä¼šè¢«ç»Ÿè®¡ï¼Œä¸”æ— éœ€ä¿®æ”¹ä¸»å¾ªç¯ä»£ç ä¹Ÿèƒ½å®ç°å…¨æ˜¾
CONFIDENCE_THRESHOLDS = {
    "PET": 0.0,
    "PA":  0.0,
    "CC":  0.0
}
ORIGINAL_BANDS = 208
OVERLAY_ALPHA = 0.90  # [æ–°] é¢„æµ‹é¢œè‰²å±‚çš„é€æ˜åº¦ (0.0~1.0)ï¼Œè¶Šå°è¶Šé€ï¼Œçº¹ç†è¶Šæ˜æ˜¾


# ================= ğŸ§¬ è‡ªå®šä¹‰å±‚å®šä¹‰ (ä¿æŒä¸å˜) =================

class SpectralAugment(layers.Layer):
    def __init__(self, shift_range=5, scale_range=0.3, noise_std=0.05, **kwargs):
        super().__init__(**kwargs)
        self.shift = shift_range;
        self.scale = scale_range;
        self.noise_std = noise_std

    def call(self, inputs, training=True): return inputs

    def get_config(self):
        config = super().get_config();
        config.update({"shift_range": self.shift, "scale_range": self.scale, "noise_std": self.noise_std});
        return config


class CascadeLogicLayer(layers.Layer):
    def __init__(self, **kwargs): super().__init__(**kwargs)

    def call(self, inputs):
        pet_prob, pa_prob = inputs
        is_pet = tf.greater(pet_prob, 0.5);
        is_pa = tf.greater(pa_prob, 0.5)
        return tf.where(is_pet, 1.0, tf.where(is_pa, 2.0, 3.0))


class PhysicsAttention(layers.Layer):
    def __init__(self, init_weights=None, **kwargs):
        super().__init__(**kwargs);
        self.init_w = init_weights

    def build(self, input_shape):
        self.phy_w = tf.constant(self.init_w, dtype=tf.float32) if self.init_w is not None else tf.ones(input_shape[-1],
                                                                                                        dtype=tf.float32)
        self.scale = self.add_weight(name='atten_scale', shape=(1,), initializer='ones', trainable=True)

    def call(self, inputs): return inputs

    def get_config(self): return super().get_config()


# ================= ğŸ› ï¸ æ ¸å¿ƒå·¥å…·ç±» =================

class ModelWrapper:
    def __init__(self, model_path):
        self.type = "keras" if model_path.endswith(".h5") else "onnx"
        print(f"ğŸ”Œ åŠ è½½æ¨¡å‹ ({self.type}): {os.path.basename(model_path)}")
        if self.type == "keras":
            self.model = tf.keras.models.load_model(model_path, compile=False,
                                                    custom_objects={"SpectralAugment": SpectralAugment,
                                                                    "CascadeLogicLayer": CascadeLogicLayer,
                                                                    "PhysicsAttention": PhysicsAttention})
        else:
            import onnxruntime as ort
            self.sess = ort.InferenceSession(model_path, providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])
            self.input_name = self.sess.get_inputs()[0].name;
            self.output_names = [o.name for o in self.sess.get_outputs()]

    def predict(self, X):
        if len(X) == 0: return np.array([]), np.array([])  # å¤„ç†ç©ºè¾“å…¥
        if self.type == "keras":
            preds = self.model.predict(X, verbose=0, batch_size=2048)
            return preds[0], preds[1]
        else:
            preds = self.sess.run(self.output_names, {self.input_name: X})
            return preds[0], preds[1]


# ================= ğŸ§ª é¢„å¤„ç†ç®—æ³• =================

def apply_snv(spectra):
    stds = np.std(spectra, axis=1, keepdims=True);
    stds[stds == 0] = 1e-6
    return (spectra - np.mean(spectra, axis=1, keepdims=True)) / stds


def apply_derivative(spectra, window=11, poly=3):
    return savgol_filter(spectra, window_length=window, polyorder=poly, deriv=1, axis=1)


def load_calibration_data(white_path, dark_path):
    def _load(p):
        hdr = os.path.splitext(p)[0] + ".hdr"
        if not os.path.exists(hdr): raise FileNotFoundError(f"Missing HDR: {hdr}")
        return np.mean(envi.open(hdr, p).load(), axis=(0, 1)).astype(np.float32)

    return _load(white_path), _load(dark_path)


def get_selected_bands_indices(config_path):
    if not os.path.exists(config_path): return list(range(416))
    with open(config_path, 'r') as f:
        data = json.load(f)
    selected = set()
    for mat in data['materials'].values(): selected.update(mat['selected_bands'])
    return sorted(list(selected))


# ================= ğŸš€ ä¼˜åŒ–çš„å•å›¾æ¨ç†æµç¨‹ =================
def process_single_image(fpath, model, white_ref, dark_ref, selected_bands_idx):
    start_t = time.time()

    # 1. åŠ è½½ ENVI
    hdr = os.path.splitext(fpath)[0] + ".hdr"
    if not os.path.exists(hdr): return None, "HDR not found"
    try:
        raw_data = envi.open(hdr, fpath).load().astype(np.float32)
        if raw_data.shape[1] < raw_data.shape[2] and raw_data.shape[1] in [206, 208, 224]:
            raw_data = np.transpose(raw_data, (0, 2, 1))
        H, W, B = raw_data.shape
    except Exception as e:
        return None, f"åŠ è½½å¤±è´¥: {e}"

    # æ ¡å‡†å¯¹é½
    if white_ref.shape[0] != B:
        w_aligned = cv2.resize(white_ref.reshape(1, -1), (B, 1), interpolation=cv2.INTER_LINEAR).flatten()
        d_aligned = cv2.resize(dark_ref.reshape(1, -1), (B, 1), interpolation=cv2.INTER_LINEAR).flatten()
    else:
        w_aligned, d_aligned = white_ref, dark_ref

    # 2. è®¡ç®—åå°„ç‡
    denom = w_aligned - d_aligned;
    denom[denom == 0] = 1e-6
    reflectance = (raw_data - d_aligned) / denom

    # æ¨¡å‹æ³¢æ®µå¯¹é½
    if B != ORIGINAL_BANDS:
        flat = reflectance.reshape(-1, B)
        flat = cv2.resize(flat, (ORIGINAL_BANDS, flat.shape[0]), interpolation=cv2.INTER_LINEAR)
        reflectance = flat.reshape(H, W, ORIGINAL_BANDS);
        B = ORIGINAL_BANDS

    # 3. ç”Ÿæˆæ©è†œ (è‡ªé€‚åº”åŠ¨æ€é˜ˆå€¼)
    # è®¡ç®—çœŸå®å…‰å¼º (å½’ä¸€åŒ–åˆ° 0~1)
    abs_intensity = np.mean(reflectance, axis=2)
    v_min = np.nanmin(abs_intensity)
    v_max = np.nanmax(abs_intensity)

    if v_max - v_min < 1e-6:
        intensity_relative = np.zeros_like(abs_intensity)
    else:
        intensity_relative = (abs_intensity - v_min) / (v_max - v_min)

    # åº”ç”¨é˜ˆå€¼
    mask_bg = intensity_relative < BRIGHTNESS_THRESHOLD
    mask_glare = intensity_relative > MAX_BRIGHTNESS_THRESHOLD
    mask_invalid = mask_bg | mask_glare

    # æ›´æ–° intensity ç”¨äºæ˜¾ç¤º
    intensity = intensity_relative

    # ================= ğŸš¨ [ä¿®å¤ç‚¹] æå‰è®¡ç®— valid_indices ğŸš¨ =================
    # å¿…é¡»åœ¨è¿™é‡Œè®¡ç®—ï¼Œå¦åˆ™ä¸‹é¢çš„ if æ£€æŸ¥ä¼šæŠ¥é”™ NameError
    valid_indices = np.where(~mask_invalid.flatten())[0]

    # ç°åœ¨å¯ä»¥å®‰å…¨åœ°è¿›è¡Œæ£€æŸ¥äº†
    if len(valid_indices) / (H * W) > 0.95:
        pass  # print("âš ï¸ è­¦å‘Š: å‡ ä¹å…¨å›¾éƒ½è¢«è¯†åˆ«ä¸ºç‰©ä½“ï¼Œå¯èƒ½èƒŒæ™¯é˜ˆå€¼å¤ªä½")
    elif len(valid_indices) / (H * W) < 0.001:
        pass  # print("âš ï¸ è­¦å‘Š: å‡ ä¹å…¨å›¾éƒ½è¢«è¿‡æ»¤äº†ï¼Œå¯èƒ½é˜ˆå€¼å¤ªé«˜")
    # ====================================================================

    # 4. ä»…å¤„ç†æœ‰æ•ˆåƒç´  (Data Initialization with NaN)
    prob_pet_map = np.full((H * W), np.nan, dtype=np.float32)
    prob_pa_map = np.full((H * W), np.nan, dtype=np.float32)

    if len(valid_indices) > 0:
        # æå–æœ‰æ•ˆåƒç´ è¿›è¡Œé¢„å¤„ç†
        X_valid = reflectance.reshape(-1, B)[valid_indices]

        # ç‰¹å¾å·¥ç¨‹
        X_snv = apply_snv(X_valid)
        X_deriv = apply_derivative(X_snv)
        X_full = np.concatenate([X_snv, X_deriv], axis=1)

        try:
            X_input = X_full[:, selected_bands_idx]
        except IndexError:
            return None, "ç‰¹å¾ç´¢å¼•è¶Šç•Œ"

        # 5. æ¨¡å‹æ¨ç†
        t_inf_start = time.time()
        p_pet, p_pa = model.predict(X_input)
        t_inf_end = time.time()

        # 6. å¡«å›å…¨å›¾çŸ©é˜µ
        prob_pet_map[valid_indices] = p_pet.flatten()
        prob_pa_map[valid_indices] = p_pa.flatten()

        inf_time = t_inf_end - t_inf_start
    else:
        inf_time = 0

    # Reshape å› 2D
    prob_pet_map = prob_pet_map.reshape(H, W)
    prob_pa_map = prob_pa_map.reshape(H, W)

    # è®¡ç®— CC (æ’é™¤æ³•)
    prob_cc_map = np.full((H, W), np.nan, dtype=np.float32)
    valid_mask_2d = ~mask_invalid

    if np.any(valid_mask_2d):
        p_pet_valid = prob_pet_map[valid_mask_2d]
        p_pa_valid = prob_pa_map[valid_mask_2d]
        prob_cc_map[valid_mask_2d] = (1.0 - p_pet_valid) * (1.0 - p_pa_valid)

    # 7. ç»Ÿè®¡
    stats = {
        "PET": np.sum(prob_pet_map[valid_mask_2d] > CONFIDENCE_THRESHOLDS["PET"]),
        "PA": np.sum(prob_pa_map[valid_mask_2d] > CONFIDENCE_THRESHOLDS["PA"]),
        "CC": np.sum(prob_cc_map[valid_mask_2d] > CONFIDENCE_THRESHOLDS["CC"])
    }

    return {
        "prob_pet": prob_pet_map,
        "prob_pa": prob_pa_map,
        "prob_cc": prob_cc_map,

        # âœ… [å¿…é¡»æ·»åŠ è¿™ä¸€è¡Œ] æŠŠåŸå§‹å¼ºåº¦å›¾ä¼ å‡ºæ¥ï¼Œä¸»ç¨‹åºè¦ç”¨å®ƒç”»å·¦è¾¹çš„å›¾
        "raw_intensity": intensity,

        "mask_invalid": mask_invalid,
        "stats": stats,
        "inf_time": inf_time,
        "total_time": time.time() - start_t
    }, None

# ================= ğŸ ä¸»ç¨‹åº =================

if __name__ == "__main__":
    if not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)

    print(f"ğŸ”§ è¯»å–é…ç½®: {CONFIG_PATH}")
    sel_bands = get_selected_bands_indices(CONFIG_PATH)

    print("ğŸ“¥ è¯»å–é»‘ç™½æ¿...")
    try:
        w_ref, d_ref = load_calibration_data(WHITE_REF, DARK_REF)
    except Exception as e:
        print(f"âŒ æ ¡å‡†å¤±è´¥: {e}"); exit()

    wrapper = ModelWrapper(MODEL_PATH)

    files = glob.glob(os.path.join(INPUT_DIR, "*.spe"))
    if not files:
        files = glob.glob(os.path.join(INPUT_DIR, "*.hdr"))
        files = [f for f in files if "ref" not in os.path.basename(f)]
        files = [f.replace(".hdr", ".spe") for f in files]

    print(f"ğŸ“‚ æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶å¾…å¤„ç†")

    for fpath in files:
        fname = os.path.basename(fpath)
        print(f"\nğŸ–¼ï¸ å¤„ç†: {fname} ...")

        res, err = process_single_image(fpath, wrapper, w_ref, d_ref, sel_bands)
        if err: print(f"   âŒ å¤±è´¥: {err}"); continue

        # === ğŸ¨ [æ ¸å¿ƒä¿®æ”¹] å åŠ çº¹ç†æ˜¾ç¤º (Overlay) ===

        H, W = res['raw_intensity'].shape
        mask = res['mask_invalid']

        # 1. å‡†å¤‡åº•å±‚ï¼šåŸå§‹çº¹ç† (Gray -> BGR)
        # å½’ä¸€åŒ–å¼ºåº¦å›¾åˆ° 0-255
        raw_norm = cv2.normalize(res['raw_intensity'], None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
        # è½¬ä¸º 3 é€šé“ BGRï¼Œä½œä¸ºåº•å›¾
        img_base = cv2.cvtColor(raw_norm, cv2.COLOR_GRAY2BGR)

        # 2. å‡†å¤‡é¡¶å±‚ï¼šAI é¢„æµ‹é¢œè‰² (RGB Probability)
        # å°† NaN æ›¿æ¢ä¸º 0
        p_pet = np.nan_to_num(res['prob_pet'], 0)
        p_pa = np.nan_to_num(res['prob_pa'], 0)
        p_cc = np.nan_to_num(res['prob_cc'], 0)

        # ================= ğŸ§¹ [å·²å–æ¶ˆ] åº”ç”¨é˜ˆå€¼è¿‡æ»¤å™ªç‚¹ =================
        # æ³¨é‡Šæ‰ä¸‹é¢ä¸‰è¡Œï¼Œå³å¯æ˜¾ç¤ºæ‰€æœ‰æ¦‚ç‡ > 0 çš„é¢„æµ‹ç»“æœï¼ˆå…¨æ˜¾æ¨¡å¼ï¼‰
        # p_pet[p_pet < CONFIDENCE_THRESHOLDS["PET"]] = 0
        # p_pa[p_pa   < CONFIDENCE_THRESHOLDS["PA"]]  = 0
        # p_cc[p_cc   < CONFIDENCE_THRESHOLDS["CC"]]  = 0
        # ============================================================
        # ============================================================

        img_color = np.zeros((H, W, 3), dtype=np.uint8)
        img_color[..., 2] = (p_pet * 255).astype(np.uint8)  # R: PET
        img_color[..., 1] = (p_pa * 255).astype(np.uint8)  # G: PA
        img_color[..., 0] = (p_cc * 255).astype(np.uint8)  # B: CC

        # 3. å åŠ èåˆ (Blending)
        # ä»…åœ¨éèƒŒæ™¯åŒºåŸŸè¿›è¡Œèåˆ
        # å…¬å¼: Output = Base * (1-alpha) + Color * alpha
        img_overlay = img_base.copy()

        # æå–å‰æ™¯åŒºåŸŸ
        fg_indices = ~mask

        # ä½¿ç”¨ addWeighted è¿›è¡Œèåˆ
        # æ³¨æ„ï¼šaddWeighted æ˜¯å…¨å›¾æ“ä½œï¼Œä¸ºäº†åªå¤„ç†å‰æ™¯ï¼Œæˆ‘ä»¬å…ˆå…¨å›¾èåˆï¼Œå†æŠŠèƒŒæ™¯æ¶‚é»‘
        # æˆ–è€…ä½¿ç”¨æ©è†œæ“ä½œ
        img_blended = cv2.addWeighted(img_base, 1.0 - OVERLAY_ALPHA, img_color, OVERLAY_ALPHA, 0)

        # 4. èƒŒæ™¯ç½®é»‘
        # å°†èƒŒæ™¯åŒºåŸŸå¼ºåˆ¶è®¾ä¸ºçº¯é»‘ [0,0,0]
        img_final_right = img_blended
        img_final_right[mask] = [0, 0, 0]

        # æ·»åŠ å›¾ä¾‹
        cv2.putText(img_final_right, "Overlay: PET(R) PA(G) CC(B)", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6,
                    (255, 255, 255), 2)

        # 5. å·¦ä¾§å¯¹æ¯”å›¾ï¼šåŸå§‹å›¾åƒ (å¸¦æ ‡é¢˜)
        img_final_left = img_base.copy()
        # å·¦ä¾§å›¾èƒŒæ™¯ä¹Ÿè®¾ä¸ºé»‘ï¼Œä¿æŒä¸€è‡´æ€§ï¼Œæˆ–è€…ä¿ç•™å™ªå£°çœ‹åŸå§‹æƒ…å†µï¼Ÿ
        # ç”¨æˆ·è¯´â€œçƒ­åŠ›å›¾ä¸­èƒŒæ™¯ä½¿ç”¨é»‘è‰²â€ï¼Œé€šå¸¸ Raw å›¾ä¿ç•™åŸæ ·æ¯”è¾ƒå¥½å¯¹æ¯”ï¼Œä½†ä¸ºäº†ç¾è§‚ä¹Ÿå¯ä»¥ Mask
        # è¿™é‡Œæˆ‘ä»¬åª Mask å³ä¾§é¢„æµ‹å›¾çš„èƒŒæ™¯ã€‚å·¦ä¾§ä¿ç•™åŸè²Œã€‚
        cv2.putText(img_final_left, "Raw Intensity", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

        # 6. æ‹¼æ¥
        combined_img = np.hstack([img_final_left, img_final_right])

        # ä¿å­˜
        base_name = os.path.splitext(fname)[0]
        vis_path = os.path.join(OUTPUT_DIR, base_name + "_overlay.png")
        cv2.imwrite(vis_path, combined_img)

        print(f"   âœ… å®Œæˆ | è€—æ—¶: {res['total_time']:.2f}s (æ¨ç† {res['inf_time'] * 1000:.0f}ms)")
        print(f"      ç»Ÿè®¡: PET={res['stats']['PET']}, PA={res['stats']['PA']}, CC={res['stats']['CC']}")
        print(f"      å·²ä¿å­˜: {vis_path}")

    print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")