import numpy as np
import matplotlib.pyplot as plt
import spectral.io.envi as envi
import os
import time
import glob
import gc
import json
import cv2

# ================= ğŸ”§ é…ç½®åŒºåŸŸ =================
# [1] æ¨¡å‹è·¯å¾„ (æ”¯æŒ .h5 æˆ– .onnx)
MODEL_PATH = r"D:\Processed_Result\67w-38w\models63w\20260123-1516-0.9999-models.h5"
#MODEL_PATH = r"D:\DRL\DRL1\models\final_pet_model.onnx"  # ä¹Ÿå¯ä»¥åˆ‡æ¢ä¸º ONNX

# [2] é…ç½®æ–‡ä»¶
CONFIG_PATH = "best_bands_config.json"

# [3] è·¯å¾„
INPUT_DIR = r"D:\Train_Data\æµ‹è¯•é›†\PET"
OUTPUT_DIR = r"D:\RESULT\Test_Result\1.231522"

# [4] æ ¡å‡†æ–‡ä»¶
WHITE_REF = r"D:\Train_Data\DWA\white_ref.spe"
DARK_REF = r"D:\Train_Data\DWA\dark_ref.spe"

# æ˜¯å¦ä¿å­˜å¯è§†åŒ–ç»“æœå›¾ç‰‡ (True=ä¿å­˜, False=ä¸ä¿å­˜)
SAVE_VISUALIZATION = True

# [5] å‚æ•°
BRIGHTNESS_THRESHOLD = 0.01
CONFIDENCE_THRESHOLD = 0.80
INFERENCE_BATCH_SIZE = 8192


# ================= ğŸ§  æ¨¡å‹åŒ…è£…ç±» (å…¼å®¹ H5/ONNX) =================
class ModelWrapper:
    def __init__(self, model_path):
        self.model_path = model_path
        self.type = "unknown"
        self.session = None
        self.tf_model = None

        if model_path.endswith(".onnx"):
            self.type = "onnx"
            try:
                import onnxruntime as ort
                # ä¼˜å…ˆä½¿ç”¨ CUDAï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨ CPU
                providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
                self.session = ort.InferenceSession(model_path, providers=providers)
                self.input_name = self.session.get_inputs()[0].name
                print(f"ğŸš€ [Engine] å·²åŠ è½½ ONNX æ¨¡å‹: {model_path}")
            except ImportError:
                print("âŒ é”™è¯¯: åŠ è½½ ONNX éœ€è¦å®‰è£… onnxruntime åº“ (pip install onnxruntime-gpu)")
                exit()
        else:
            self.type = "keras"
            try:
                import tensorflow as tf
                # åŠ è½½å®Œæ•´æ¨¡å‹ (åŒ…å«ç»“æ„)ï¼Œä¸éœ€è¦å† build_model
                # éœ€è¦æä¾›è‡ªå®šä¹‰å±‚ transformer_encoderï¼Œå¦åˆ™ä¼šæŠ¥é”™
                self.tf_model = tf.keras.models.load_model(
                    model_path,
                    custom_objects={'transformer_encoder': transformer_encoder}
                )
                print(f"ğŸš€ [Engine] å·²åŠ è½½ Keras H5 æ¨¡å‹: {model_path}")
            except Exception as e:
                print(f"âŒ Keras æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                exit()

    def predict(self, input_data):
        """
        ç»Ÿä¸€é¢„æµ‹æ¥å£
        input_data: (Batch, Bands)
        """
        if self.type == "onnx":
            # ONNX æ¨ç†
            input_feed = {self.input_name: input_data.astype(np.float32)}
            # session.run è¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ªè¾“å‡º
            preds = self.session.run(None, input_feed)[0]
            return preds
        elif self.type == "keras":
            # Keras æ¨ç†
            return self.tf_model.predict(input_data, batch_size=INFERENCE_BATCH_SIZE, verbose=0)


# ================= ğŸ› ï¸ è¾…åŠ©å‡½æ•°å®šä¹‰ =================
# ä¸ºäº†åŠ è½½ H5ï¼Œå¿…é¡»å®šä¹‰è¿™ä¸ª layer (å¦‚æœæ¨¡å‹é‡Œæœ‰çš„è¯)
def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):
    import tensorflow as tf
    from tensorflow.keras import layers
    x = layers.LayerNormalization(epsilon=1e-6)(inputs)
    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)
    x = layers.Dropout(dropout)(x)
    res = x + inputs
    x = layers.LayerNormalization(epsilon=1e-6)(res)
    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation="relu")(x)
    x = layers.Dropout(dropout)(x)
    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)
    return x + res


def fix_header_byte_order(hdr_path):
    if not os.path.exists(hdr_path): return
    try:
        with open(hdr_path, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
        if not any('byte order' in line.lower() for line in lines):
            with open(hdr_path, 'a') as f: f.write('\nbyte order = 0')
    except:
        pass


def resolve_paths(file_path):
    base = os.path.splitext(file_path)[0]
    hdr = base + ".hdr"
    spe = base + ".spe"
    if not os.path.exists(spe) and os.path.exists(base): spe = base
    return hdr, spe


def safe_extract_bands(raw_img, bands_indices):
    """
    å®‰å…¨æå–æ³¢æ®µ (ç´¢å¼•é’³åˆ¶)
    """
    H, W, C = raw_img.shape
    safe_indices = [min(b, C - 1) for b in bands_indices]
    return raw_img[:, :, safe_indices], safe_indices


def load_calibration_bands(path, bands_indices):
    """
    åªåŠ è½½ç‰¹å®šæ³¢æ®µçš„æ ¡å‡†æ•°æ®ï¼Œå‡å°‘å†…å­˜å ç”¨
    """
    hdr, spe = resolve_paths(path)
    fix_header_byte_order(hdr)
    if not os.path.exists(spe): raise FileNotFoundError(f"Missing: {spe}")

    # åŠ è½½å…¨è°±æ ¡å‡†
    img = envi.open(hdr, spe).load()
    mean_spec = np.mean(img, axis=(0, 1)).astype(np.float32)

    # å®‰å…¨åˆ‡ç‰‡
    C = len(mean_spec)
    safe_indices = [min(b, C - 1) for b in bands_indices]

    return mean_spec[safe_indices]


# ================= ğŸ” å•å›¾å¤„ç†é€»è¾‘ =================
def process_single_image(input_path, engine, white_sel, dark_sel, selected_bands):
    filename = os.path.basename(input_path)
    t_start = time.time()

    # 1. åŠ è½½å›¾åƒ
    hdr, spe = resolve_paths(input_path)
    fix_header_byte_order(hdr)
    try:
        raw_img = envi.open(hdr, spe).load()
    except Exception as e:
        return None, f"æ–‡ä»¶æŸå: {e}"

    # ç»´åº¦ä¿®æ­£
    if raw_img.shape[1] > 200 and raw_img.shape[1] < 230 and raw_img.shape[2] != raw_img.shape[1]:
        # ç®€å•åˆ¤æ–­æ³¢æ®µç»´åº¦æ˜¯å¦åœ¨ç¬¬äºŒä¸ªä½ç½®
        raw_img = np.transpose(raw_img, (0, 2, 1))

    H, W, TotalBands = raw_img.shape

    # 2. å®‰å…¨æå–ç‰¹å¾æ³¢æ®µ (Raw DN)
    raw_sel, _ = safe_extract_bands(raw_img, selected_bands)
    raw_sel = raw_sel.astype(np.float32)

    # 3. è¾å°„æ ¡å‡† (åªè®¡ç®—è¿™30ä¸ªæ³¢æ®µ)
    diff = (white_sel - dark_sel)
    diff[diff == 0] = 1e-6
    reflectance = (raw_sel - dark_sel) / diff

    # 4. äº®åº¦ Mask (åŸºäº30ä¸ªæ³¢æ®µçš„å¹³å‡äº®åº¦)
    mean_intensity = np.mean(reflectance, axis=2)
    dynamic_thresh = max(BRIGHTNESS_THRESHOLD, np.max(mean_intensity) * 0.1)
    valid_mask = mean_intensity > dynamic_thresh

    final_map = np.zeros((H, W), dtype=np.float32)
    inf_time = 0

    if np.sum(valid_mask) > 0:
        valid_pixels = reflectance[valid_mask]

        # 5. Min-Max å½’ä¸€åŒ– (Pixel-wise)
        p_min = np.min(valid_pixels, axis=1, keepdims=True)
        p_max = np.max(valid_pixels, axis=1, keepdims=True)
        denom = p_max - p_min
        denom[denom < 1e-6] = 1.0

        model_input = (valid_pixels - p_min) / denom

        # 6. AI æ¨ç† (å…¼å®¹ ONNX/Keras)
        t0 = time.time()
        preds = engine.predict(model_input)
        inf_time = time.time() - t0

        # 7. ç»“æœè¿‡æ»¤
        prob_pet = preds  # å‡è®¾è¾“å‡ºæ˜¯ PET æ¦‚ç‡ (Sigmoid)
        # å¦‚æœè®­ç»ƒæ ‡ç­¾æ˜¯åçš„ (0=PET)ï¼Œè¿™é‡Œéœ€è¦ 1-preds
        # æ ¹æ® save_data.py, PET=1, æ‰€ä»¥ç›´æ¥ç”¨ preds

        final_decision = np.where(prob_pet > CONFIDENCE_THRESHOLD, 1.0, 0.0)
        final_map[valid_mask] = final_decision.flatten()

    return {
        'map': final_map,
        'raw': raw_img,  # è¿”å›åŸå›¾ç”¨äºå¯è§†åŒ–
        'inf_time': inf_time,
        'total_time': time.time() - t_start
    }, None


# ================= ä¸»ç¨‹åº =================
if __name__ == "__main__":
    if not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)

    # 1. åŠ è½½æ³¢æ®µé…ç½®
    if os.path.exists(CONFIG_PATH):
        with open(CONFIG_PATH, 'r') as f:
            SELECTED_BANDS = json.load(f).get("selected_bands", [])
        print(f"ğŸ¤– [Config] ç‰¹å¾æ³¢æ®µæ•°: {len(SELECTED_BANDS)}")
    else:
        print("âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ï¼")
        exit()

    # 2. åˆå§‹åŒ–æ¨ç†å¼•æ“ (è‡ªåŠ¨è¯†åˆ« H5/ONNX)
    engine = ModelWrapper(MODEL_PATH)

    # 3. é¢„åŠ è½½æ ¡å‡†æ•°æ® (åªåˆ‡ç‰‡å‡ºéœ€è¦çš„æ³¢æ®µ)
    print("ğŸ“¥ å‡†å¤‡æ ¡å‡†æ•°æ®...")
    try:
        white_sel = load_calibration_bands(WHITE_REF, SELECTED_BANDS)
        dark_sel = load_calibration_bands(DARK_REF, SELECTED_BANDS)
    except Exception as e:
        print(f"âŒ æ ¡å‡†æ–‡ä»¶é”™è¯¯: {e}")
        exit()

    # 4. æ‰¹å¤„ç†
    files = glob.glob(os.path.join(INPUT_DIR, "*.spe"))
    print(f"ğŸ“‚ å‘ç° {len(files)} ä¸ªå¾…æµ‹æ–‡ä»¶")

    for fpath in files:
        fname = os.path.basename(fpath)
        res, err = process_single_image(fpath, engine, white_sel, dark_sel, SELECTED_BANDS)

        if err:
            print(f"âŒ {fname}: {err}")
        else:
            print(f"âœ… {fname} | æ¨ç†: {res['inf_time'] * 1000:.1f}ms | æ€»æ—¶: {res['total_time']:.2f}s")

            # ä¿å­˜ç»“æœå›¾
            if SAVE_VISUALIZATION:
                plt.figure(figsize=(10, 5))
                plt.subplot(1, 2, 1);
                plt.imshow(res['raw'][:, :, 100], cmap='gray');
                plt.title("Raw")
                plt.subplot(1, 2, 2);
                plt.imshow(res['map'], cmap='jet', vmin=0, vmax=1);
                plt.title("AI Result")
                plt.savefig(os.path.join(OUTPUT_DIR, fname + ".png"))
                plt.close()